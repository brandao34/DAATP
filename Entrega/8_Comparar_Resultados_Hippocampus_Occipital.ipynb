{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Hippo:\n",
      "(305, 2014)\n",
      "Shape Occipital:\n",
      "(305, 2026)\n"
     ]
    }
   ],
   "source": [
    "df_hippo_original = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/1_DF_CN-MCI_1_After_Pre_Processamento.csv') \n",
    "df_ocipital_original = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/1_Occipital_pre_processamento.csv') \n",
    "\n",
    "print(\"Shape Hippo:\")\n",
    "print(df_hippo_original.shape)\n",
    "\n",
    "print(\"Shape Occipital:\")\n",
    "print(df_ocipital_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(data, target, threshold):\n",
    "    \"\"\"\n",
    "    Remove features altamente correlacionadas, mantendo a que tem maior correlação com o target.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame contendo as features.\n",
    "        target (pd.Series): Coluna com os valores do target.\n",
    "        threshold (float): Valor de correlação acima do qual consideramos features altamente correlacionadas.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com as colunas altamente correlacionadas removidas.\n",
    "        set: Conjunto das colunas removidas.\n",
    "    \"\"\"\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = data.corr().abs()\n",
    "    \n",
    "    # Compute correlation of each feature with the target\n",
    "    target_corr = data.corrwith(data['Transition']).abs()\n",
    "    \n",
    "    # Identify columns to remove based on correlation\n",
    "    to_drop = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] >= threshold:\n",
    "                col_i = corr_matrix.columns[i]\n",
    "                col_j = corr_matrix.columns[j]\n",
    "                \n",
    "                # Remove the column with lower correlation with the target\n",
    "                if target_corr[col_i] < target_corr[col_j]:\n",
    "                    to_drop.add(col_i)\n",
    "                else:\n",
    "                    to_drop.add(col_j)\n",
    "\n",
    "    # Drop the identified columns\n",
    "    data_final = data.drop(columns=to_drop)\n",
    "\n",
    "    return data_final, to_drop\n",
    "\n",
    "\n",
    "\n",
    "def remove_low_variance_features(data, threshold):\n",
    "    \"\"\"\n",
    "    Remove columns with a standard deviation below the given threshold.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        threshold (float): The minimum standard deviation a column must have to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A DataFrame with low-variance columns removed.\n",
    "            - list: A list of columns that were removed.\n",
    "    \"\"\"\n",
    "    # Calculate the standard deviation for each column\n",
    "    std_dev = data.std()\n",
    "\n",
    "    # Identify columns to keep (standard deviation above threshold)\n",
    "    retained_columns = std_dev[std_dev > threshold].index\n",
    "\n",
    "    # Identify columns to remove\n",
    "    removed_columns = std_dev[std_dev <= threshold].index\n",
    "\n",
    "    # Create a new DataFrame with only the retained columns\n",
    "    data_reduced = data[retained_columns]\n",
    "\n",
    "    return data_reduced, removed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Do data_set Final do Hippocampus  \n",
      "(305, 348)\n",
      "\n",
      "\n",
      "Shape Do data_set Final do Occipital \n",
      "(305, 354)\n"
     ]
    }
   ],
   "source": [
    "df_hippo_Randon_Forest = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/2_data_Random_Forest_Clean.csv')\n",
    "\n",
    "X_cleaned, to_drop = remove_highly_correlated_features(df_ocipital_original, 'Transition', 0.81)\n",
    "\n",
    "data_occipital_rf = df_ocipital_original.drop(columns=to_drop,axis=1)\n",
    "\n",
    "data_, to_drop_2 = remove_low_variance_features(X_cleaned, 0.005)\n",
    "\n",
    "data_ocipital_final = data_occipital_rf.drop(columns=to_drop_2,axis=1, errors='ignore')\n",
    "\n",
    "print(\"Shape Do data_set Final do Hippocampus  \")\n",
    "print(df_hippo_Randon_Forest.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Shape Do data_set Final do Occipital \")\n",
    "print(data_ocipital_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Occipital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.17580618 0.17794058 0.25709866 0.24403342 0.26589744]\n",
      "Cross Validation Score Média: 0.22415525626289048\n",
      "Cross Validation Score STD: 0.03923327292913626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_ocipital = data_ocipital_final.drop('Transition', axis=1)\n",
    "y_ocipital = data_ocipital_final['Transition']\n",
    "\n",
    "\n",
    "rf_ocipital = RandomForestClassifier(n_estimators=143, max_features = 'sqrt', max_depth= 24, min_samples_split=32, min_samples_leaf=13, bootstrap=False,class_weight = 'balanced',random_state=34)\n",
    "rf_ocipital_score = cross_val_score(rf_ocipital, X_ocipital, y_ocipital, cv=5,scoring='f1_macro')\n",
    "print(f\"Cross Validation Score: {rf_ocipital_score}\")\n",
    "print(f\"Cross Validation Score Média: {rf_ocipital_score.mean()}\")\n",
    "print(f\"Cross Validation Score STD: {rf_ocipital_score.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Do data_set Final do Hippocampus  \n",
      "(305, 412)\n",
      "\n",
      "\n",
      "Shape Do data_set Final do Occipital \n",
      "(305, 414)\n"
     ]
    }
   ],
   "source": [
    "df_hippo_xgboost = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/2_data_XGBoost.csv')\n",
    "\n",
    "X_cleaned, to_drop = remove_highly_correlated_features(df_ocipital_original, 'Transition', 0.82)\n",
    "\n",
    "data_occipital_xg = df_ocipital_original.drop(columns=to_drop,axis=1)\n",
    "\n",
    "\n",
    "print(\"Shape Do data_set Final do Hippocampus  \")\n",
    "print(df_hippo_xgboost.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Shape Do data_set Final do Occipital \")\n",
    "print(data_occipital_xg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_ocipital_xg = data_occipital_xg.drop('Transition', axis=1)\n",
    "y_ocipital_xg = data_occipital_xg['Transition']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Occipital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.20342171 0.21553805 0.23539686 0.29826134 0.22008276]\n",
      "Cross Validation Score Média: 0.2345401461823901\n",
      "Cross Validation Score STD: 0.033465138375488875\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier(n_estimators= 846, max_depth=  5, learning_rate= 0.1660773939789664, subsample= 0.9293091645826319, colsample_bytree =  0.5898888173202074, gamma =0.0035106908632086685, reg_alpha =  3.3065806009993237e-06, reg_lambda = 0.6447155795041164, min_child_weight= 7)\n",
    "\n",
    "\n",
    "xgboost_score_ocii = cross_val_score(xgboost_model, X_ocipital_xg, y_ocipital_xg, cv=5,scoring='f1_macro')\n",
    "\n",
    "print(f\"Cross Validation Score: {xgboost_score_ocii}\")\n",
    "print(f\"Cross Validation Score Média: {xgboost_score_ocii.mean()}\")\n",
    "print(f\"Cross Validation Score STD: {xgboost_score_ocii.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra TRees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Do data_set Final do Hippocampus  \n",
      "(305, 812)\n",
      "\n",
      "\n",
      "Shape Do data_set Final do Occipital \n",
      "(305, 743)\n"
     ]
    }
   ],
   "source": [
    "df_hippo_extra_trees = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/2_data_ExtraTrees.csv')\n",
    "\n",
    "X_cleaned, to_drop = remove_highly_correlated_features(df_ocipital_original, 'Transition', 0.93)\n",
    "\n",
    "data_occipital_xg = df_ocipital_original.drop(columns=to_drop,axis=1)\n",
    "\n",
    "\n",
    "print(\"Shape Do data_set Final do Hippocampus  \")\n",
    "print(df_hippo_extra_trees.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Shape Do data_set Final do Occipital \")\n",
    "print(data_occipital_xg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_ocipital_xg = data_occipital_xg.drop('Transition', axis=1)\n",
    "y_ocipital_xg = data_occipital_xg['Transition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.25083061 0.15461747 0.25568173 0.22645687 0.21468013]\n",
      "Cross Validation Score Média: 0.22045336274387486\n",
      "Cross Validation Score STD: 0.036242384876576\n"
     ]
    }
   ],
   "source": [
    "extra_trees_model = ExtraTreesClassifier( n_estimators=111, max_features='sqrt',max_depth=54, min_samples_split=14, min_samples_leaf=4 , bootstrap=False, class_weight='balanced',criterion='gini' , random_state=34)\n",
    "\n",
    "\n",
    "extra_trees_score_ocii = cross_val_score(extra_trees_model, X_ocipital_xg, y_ocipital_xg, cv=5,scoring='f1_macro')\n",
    "\n",
    "print(f\"Cross Validation Score: {extra_trees_score_ocii}\")\n",
    "print(f\"Cross Validation Score Média: {extra_trees_score_ocii.mean()}\")\n",
    "print(f\"Cross Validation Score STD: {extra_trees_score_ocii.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Do data_set Final do Hippocampus  \n",
      "(305, 434)\n",
      "\n",
      "\n",
      "Shape Do data_set Final do Occipital \n",
      "(305, 432)\n"
     ]
    }
   ],
   "source": [
    "df_hippo_gradient_boost = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/2_data_GradientBoost.csv')\n",
    "\n",
    "X_cleaned, to_drop = remove_highly_correlated_features(df_ocipital_original, 'Transition', 0.83)\n",
    "\n",
    "data_occipital_xg = df_ocipital_original.drop(columns=to_drop,axis=1)\n",
    "\n",
    "\n",
    "print(\"Shape Do data_set Final do Hippocampus  \")\n",
    "print(df_hippo_gradient_boost.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Shape Do data_set Final do Occipital \")\n",
    "print(data_occipital_xg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_ocipital_xg = data_occipital_xg.drop('Transition', axis=1)\n",
    "y_ocipital_xg = data_occipital_xg['Transition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.20585895 0.25323459 0.18225108 0.28791248 0.25851371]\n",
      "Cross Validation Score Média: 0.23755416213936426\n",
      "Cross Validation Score STD: 0.03816845732774831\n"
     ]
    }
   ],
   "source": [
    "gb_model_norm = GradientBoostingClassifier(learning_rate=0.04471222414633008, n_estimators=109, max_depth=3, min_samples_split=18, min_samples_leaf=1, subsample=1.0, max_features='sqrt',random_state=34)\n",
    "\n",
    "\n",
    "gb_socre = cross_val_score(gb_model_norm, X_ocipital_xg, y_ocipital_xg, cv=5,scoring='f1_macro')\n",
    "\n",
    "print(f\"Cross Validation Score: {gb_socre}\")\n",
    "print(f\"Cross Validation Score Média: {gb_socre.mean()}\")\n",
    "print(f\"Cross Validation Score STD: {gb_socre.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo           | **Média (Hippo)** | **Desvio Padrão (Hippo)** | **Média (Occipital)** | **Desvio Padrão (Occipital)** | **Diferença (Hippo - Occipital)** |\n",
    "|:----------------:|:-----------------:|:-------------------------:|:---------------------:|:-----------------------------:|:---------------------------------:|\n",
    "| Random Forest    |      **0.3952**   |          **0.0625**       |       **0.2241**      |           **0.0392**          |             **0.1711**            |\n",
    "| XGBoost          |      **0.3630**   |          **0.0495**       |       **0.2345**      |           **0.03346**         |             **0.1285**            |\n",
    "| ExtraTrees       |      **0.3676**   |          **0.0533**       |       **0.2204**      |           **0.036**           |             **0.1472**            |\n",
    "| GradientBoost    |      **0.3736**   |          **0.0696**       |       **0.2375**      |           **0.038**           |             **0.1361**            |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
