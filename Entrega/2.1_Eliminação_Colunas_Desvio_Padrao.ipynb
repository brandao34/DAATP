{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/1_DF_CN-MCI_1_After_Pre_Processamento.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Entrega/1_DF_Test_1_After_Pre_Processamento.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desvio Padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_low_variance_features(data, threshold):\n",
    "    \"\"\"\n",
    "    Remove columns with a standard deviation below the given threshold.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        threshold (float): The minimum standard deviation a column must have to be retained.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: A DataFrame with low-variance columns removed.\n",
    "            - list: A list of columns that were removed.\n",
    "    \"\"\"\n",
    "    # Calculate the standard deviation for each column\n",
    "    std_dev = data.std()\n",
    "\n",
    "    # Identify columns to keep (standard deviation above threshold)\n",
    "    retained_columns = std_dev[std_dev > threshold].index\n",
    "\n",
    "    # Identify columns to remove\n",
    "    removed_columns = std_dev[std_dev <= threshold].index\n",
    "\n",
    "    # Create a new DataFrame with only the retained columns\n",
    "    data_reduced = data[retained_columns]\n",
    "\n",
    "    return data_reduced, removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *!  df.to_csv('DF_1_After_Pre_Processamento.csv', index=False)\n",
    "# *! ## df_test.to_csv('DF_Test_1_After_Pre_Processamento.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao Axuliar: Matrix de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que testa todos os nossos modelos que estamos a analisar, consuante um certo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração Dos Vários datasets para os vários modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_ExtraTrees,_ = remove_highly_correlated_features(df,'Transition',0.93)\n",
    "#data_Random_Forest,_ = remove_highly_correlated_features(df,'Transition',0.81)\n",
    "#data_GradientBoost,_ = remove_highly_correlated_features(df,'Transition',0.83)\n",
    "#data_XGBoost,_ = remove_highly_correlated_features(df,'Transition',0.82)\n",
    "#\n",
    "#data_ExtraTrees.to_csv('2_data_ExtraTrees.csv', index=False)\n",
    "#data_Random_Forest.to_csv('2_data_Random_Forest.csv', index=False)\n",
    "#data_GradientBoost.to_csv('2_data_GradientBoost.csv', index=False)\n",
    "#data_XGBoost.to_csv('2_data_XGBoost.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop('Transition', axis=1)\n",
    "#y = df['Transition']\n",
    "#\n",
    "#_ = train_and_predict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_random_forest(X,y): \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34, stratify=y)\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=34)\n",
    "\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Faz previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calcula e armazena o relatório de classificação\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    # Calcula e armazena o F1 Macro Score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"Model  (Random_Forest):\\n{}\".format(report))\n",
    "    print(\"F1_Macro: {:.5f}\".format(f1))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return f1 \n",
    "\n",
    "def train_and_predict_extra_trees(X,y): \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34, stratify=y)\n",
    "\n",
    "\n",
    "    model =   ExtraTreesClassifier(criterion='gini', max_depth=20, random_state=34)\n",
    "\n",
    "\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Faz previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calcula e armazena o relatório de classificação\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    # Calcula e armazena o F1 Macro Score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"Model  (Random_Forest):\\n{}\".format(report))\n",
    "    print(\"F1_Macro: {:.5f}\".format(f1))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return f1 \n",
    "\n",
    "def train_and_predict_Gradient_Boost(X,y): \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34, stratify=y)\n",
    "\n",
    "\n",
    "    model =     GradientBoostingClassifier(\n",
    "        learning_rate=0.1, n_estimators=100, random_state=34\n",
    "    )\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Faz previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calcula e armazena o relatório de classificação\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    # Calcula e armazena o F1 Macro Score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"Model  (Random_Forest):\\n{}\".format(report))\n",
    "    print(\"F1_Macro: {:.5f}\".format(f1))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return f1 \n",
    "\n",
    "def train_and_predict_XGBOOST(X,y): \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34, stratify=y)\n",
    "\n",
    "\n",
    "    model =  XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "\n",
    "\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    # Faz previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calcula e armazena o relatório de classificação\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    # Calcula e armazena o F1 Macro Score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(\"Model  (Random_Forest):\\n{}\".format(report))\n",
    "    print(\"F1_Macro: {:.5f}\".format(f1))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return f1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler CSV melhor para cada Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_ExtraTrees = pd.read_csv('2_data_ExtraTrees.csv')\n",
    "data_Random_Forest = pd.read_csv('2_data_Random_Forest.csv')\n",
    "data_GradientBoost = pd.read_csv('2_data_GradientBoost.csv')\n",
    "data_XGBoost = pd.read_csv('2_data_XGBoost.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing threshold: 0.001\n",
      "\n",
      "\n",
      "Threshold: 0.001, Features removed: 10, Remaining features: 375\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.63        24\n",
      "           1       0.54      0.47      0.50        15\n",
      "           2       0.33      0.35      0.34        17\n",
      "           3       0.29      0.11      0.16        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.45        77\n",
      "   macro avg       0.33      0.35      0.33        77\n",
      "weighted avg       0.41      0.45      0.41        77\n",
      "\n",
      "F1_Macro: 0.32756\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.001, Features removed: 33, Remaining features: 779\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67        24\n",
      "           1       0.53      0.53      0.53        15\n",
      "           2       0.25      0.24      0.24        17\n",
      "           3       0.30      0.17      0.21        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.45        77\n",
      "   macro avg       0.33      0.35      0.33        77\n",
      "weighted avg       0.40      0.45      0.42        77\n",
      "\n",
      "F1_Macro: 0.33134\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.001, Features removed: 10, Remaining features: 424\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60        24\n",
      "           1       0.75      0.60      0.67        15\n",
      "           2       0.41      0.41      0.41        17\n",
      "           3       0.32      0.39      0.35        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.49        77\n",
      "   macro avg       0.41      0.41      0.41        77\n",
      "weighted avg       0.49      0.49      0.49        77\n",
      "\n",
      "F1_Macro: 0.40569\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.001, Features removed: 10, Remaining features: 402\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.75      0.63        24\n",
      "           1       0.55      0.40      0.46        15\n",
      "           2       0.33      0.35      0.34        17\n",
      "           3       0.33      0.28      0.30        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.45        77\n",
      "   macro avg       0.35      0.36      0.35        77\n",
      "weighted avg       0.43      0.45      0.43        77\n",
      "\n",
      "F1_Macro: 0.34780\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.002\n",
      "\n",
      "\n",
      "Threshold: 0.002, Features removed: 15, Remaining features: 370\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60        24\n",
      "           1       0.54      0.47      0.50        15\n",
      "           2       0.21      0.24      0.22        17\n",
      "           3       0.25      0.17      0.20        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.40        77\n",
      "   macro avg       0.30      0.32      0.30        77\n",
      "weighted avg       0.37      0.40      0.38        77\n",
      "\n",
      "F1_Macro: 0.30374\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.002, Features removed: 53, Remaining features: 759\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.68        24\n",
      "           1       0.50      0.40      0.44        15\n",
      "           2       0.18      0.18      0.18        17\n",
      "           3       0.40      0.22      0.29        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.33      0.33      0.32        77\n",
      "weighted avg       0.40      0.44      0.40        77\n",
      "\n",
      "F1_Macro: 0.31681\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.002, Features removed: 15, Remaining features: 419\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.55        24\n",
      "           1       0.70      0.47      0.56        15\n",
      "           2       0.32      0.41      0.36        17\n",
      "           3       0.32      0.39      0.35        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.38      0.36      0.36        77\n",
      "weighted avg       0.46      0.44      0.44        77\n",
      "\n",
      "F1_Macro: 0.36443\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.002, Features removed: 15, Remaining features: 397\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70        24\n",
      "           1       0.50      0.53      0.52        15\n",
      "           2       0.29      0.24      0.26        17\n",
      "           3       0.29      0.22      0.25        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.34      0.36      0.35        77\n",
      "weighted avg       0.42      0.47      0.43        77\n",
      "\n",
      "F1_Macro: 0.34519\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.003\n",
      "\n",
      "\n",
      "Threshold: 0.003, Features removed: 21, Remaining features: 364\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73        24\n",
      "           1       0.53      0.53      0.53        15\n",
      "           2       0.35      0.35      0.35        17\n",
      "           3       0.56      0.28      0.37        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.53        77\n",
      "   macro avg       0.41      0.42      0.40        77\n",
      "weighted avg       0.50      0.53      0.50        77\n",
      "\n",
      "F1_Macro: 0.39800\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.003, Features removed: 69, Remaining features: 743\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.83      0.65        24\n",
      "           1       0.39      0.47      0.42        15\n",
      "           2       0.00      0.00      0.00        17\n",
      "           3       0.30      0.17      0.21        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.39        77\n",
      "   macro avg       0.24      0.29      0.26        77\n",
      "weighted avg       0.31      0.39      0.33        77\n",
      "\n",
      "F1_Macro: 0.25674\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.003, Features removed: 23, Remaining features: 411\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.65        24\n",
      "           1       0.56      0.33      0.42        15\n",
      "           2       0.30      0.35      0.32        17\n",
      "           3       0.30      0.33      0.32        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.35      0.35      0.34        77\n",
      "weighted avg       0.43      0.44      0.43        77\n",
      "\n",
      "F1_Macro: 0.34213\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.003, Features removed: 23, Remaining features: 389\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69        24\n",
      "           1       0.47      0.47      0.47        15\n",
      "           2       0.33      0.29      0.31        17\n",
      "           3       0.15      0.11      0.13        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.31      0.34      0.32        77\n",
      "weighted avg       0.38      0.44      0.41        77\n",
      "\n",
      "F1_Macro: 0.31957\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.004\n",
      "\n",
      "\n",
      "Threshold: 0.004, Features removed: 33, Remaining features: 352\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58        24\n",
      "           1       0.47      0.47      0.47        15\n",
      "           2       0.20      0.12      0.15        17\n",
      "           3       0.21      0.17      0.19        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.39        77\n",
      "   macro avg       0.27      0.30      0.28        77\n",
      "weighted avg       0.33      0.39      0.35        77\n",
      "\n",
      "F1_Macro: 0.27659\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.004, Features removed: 93, Remaining features: 719\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.65        24\n",
      "           1       0.50      0.47      0.48        15\n",
      "           2       0.25      0.24      0.24        17\n",
      "           3       0.33      0.11      0.17        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.32      0.34      0.31        77\n",
      "weighted avg       0.39      0.44      0.39        77\n",
      "\n",
      "F1_Macro: 0.30760\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.004, Features removed: 38, Remaining features: 396\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64        24\n",
      "           1       0.50      0.47      0.48        15\n",
      "           2       0.32      0.35      0.33        17\n",
      "           3       0.40      0.33      0.36        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.36      0.37      0.36        77\n",
      "weighted avg       0.44      0.47      0.45        77\n",
      "\n",
      "F1_Macro: 0.36425\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.004, Features removed: 35, Remaining features: 377\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64        24\n",
      "           1       0.50      0.47      0.48        15\n",
      "           2       0.21      0.18      0.19        17\n",
      "           3       0.36      0.28      0.31        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.32      0.34      0.33        77\n",
      "weighted avg       0.40      0.44      0.41        77\n",
      "\n",
      "F1_Macro: 0.32657\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.005\n",
      "\n",
      "\n",
      "Threshold: 0.005, Features removed: 37, Remaining features: 348\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.68        24\n",
      "           1       0.71      0.67      0.69        15\n",
      "           2       0.40      0.35      0.38        17\n",
      "           3       0.50      0.28      0.36        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.55        77\n",
      "   macro avg       0.43      0.43      0.42        77\n",
      "weighted avg       0.52      0.55      0.51        77\n",
      "\n",
      "F1_Macro: 0.41984\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.005, Features removed: 103, Remaining features: 709\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.88      0.68        24\n",
      "           1       0.44      0.53      0.48        15\n",
      "           2       0.08      0.06      0.07        17\n",
      "           3       0.22      0.11      0.15        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        77\n",
      "   macro avg       0.26      0.32      0.28        77\n",
      "weighted avg       0.33      0.42      0.36        77\n",
      "\n",
      "F1_Macro: 0.27588\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.005, Features removed: 43, Remaining features: 391\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64        24\n",
      "           1       0.50      0.33      0.40        15\n",
      "           2       0.26      0.29      0.28        17\n",
      "           3       0.37      0.39      0.38        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        77\n",
      "   macro avg       0.34      0.34      0.34        77\n",
      "weighted avg       0.42      0.44      0.43        77\n",
      "\n",
      "F1_Macro: 0.33953\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Threshold: 0.005, Features removed: 40, Remaining features: 372\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.75      0.62        24\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.36      0.29      0.32        17\n",
      "           3       0.25      0.22      0.24        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.43        77\n",
      "   macro avg       0.32      0.33      0.32        77\n",
      "weighted avg       0.39      0.43      0.40        77\n",
      "\n",
      "F1_Macro: 0.32143\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summary of Results:\n",
      "Threshold: 0.001, Features removed: 10, Remaining features: 375, Random Forest: 0.32755555555555554, Extra Trees: 0.3313419913419913, Gradient Boost: 0.4056862745098039, XGBoost: 0.3478009709588657\n",
      "Threshold: 0.002, Features removed: 15, Remaining features: 370, Random Forest: 0.30374269005847954, Extra Trees: 0.3168097346465468, Gradient Boost: 0.3644331696672123, XGBoost: 0.3451895868704018\n",
      "Threshold: 0.003, Features removed: 21, Remaining features: 364, Random Forest: 0.39799564270152504, Extra Trees: 0.2567378857701438, Gradient Boost: 0.34212532370427107, XGBoost: 0.3195708194289952\n",
      "Threshold: 0.004, Features removed: 33, Remaining features: 352, Random Forest: 0.2765919952210275, Extra Trees: 0.3076006751868821, Gradient Boost: 0.3642475503243232, XGBoost: 0.32657496087931975\n",
      "Threshold: 0.005, Features removed: 37, Remaining features: 348, Random Forest: 0.419843476879072, Extra Trees: 0.2758763010153443, Gradient Boost: 0.33953311802368413, XGBoost: 0.3214271693104383\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "all_results = []  # Lista para armazenar os resultados\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Testing threshold: {threshold}\\n\\n\")\n",
    "    \n",
    "    result_entry = {\n",
    "        'threshold': threshold,\n",
    "        'features_removed': None,  # Atualizado depois\n",
    "        'remaining_features': None,  # Atualizado depois\n",
    "        'F1_score_Random_Forest': None,\n",
    "        'F1_score_Extra_trees': None,\n",
    "        'F1_score_Gradient_Boost': None,\n",
    "        'F1_score_XGBOOST': None\n",
    "    }\n",
    "    \n",
    "    # ? ######### RANDOM_FOREST\n",
    "    X_cleaned, to_drop = remove_low_variance_features(data_Random_Forest, threshold)\n",
    "    X_Limpo = X_cleaned.drop('Transition', axis=1)\n",
    "    y = X_cleaned['Transition']\n",
    "    print(f\"Threshold: {threshold}, Features removed: {len(to_drop)}, Remaining features: {X_cleaned.shape[1]}\")\n",
    "    results = train_and_predict_random_forest(X_Limpo, y)\n",
    "    result_entry['F1_score_Random_Forest'] = results\n",
    "    result_entry['features_removed'] = len(to_drop)\n",
    "    result_entry['remaining_features'] = X_cleaned.shape[1]\n",
    "    print(\"\\n\\n\\n ##########################################\\n\\n\\n\")\n",
    "    \n",
    "    # ? ######### EXTRA_TREES\n",
    "    X_cleaned, to_drop = remove_low_variance_features(data_ExtraTrees, threshold)\n",
    "    X_Limpo = X_cleaned.drop('Transition', axis=1)\n",
    "    y = X_cleaned['Transition']\n",
    "    print(f\"Threshold: {threshold}, Features removed: {len(to_drop)}, Remaining features: {X_cleaned.shape[1]}\")\n",
    "    results = train_and_predict_extra_trees(X_Limpo, y)\n",
    "    result_entry['F1_score_Extra_trees'] = results\n",
    "    print(\"\\n\\n\\n ##########################################\\n\\n\\n\")\n",
    "    \n",
    "    # ? ######### GRADIENT_BOOSTING\n",
    "    X_cleaned, to_drop = remove_low_variance_features(data_GradientBoost, threshold)\n",
    "    X_Limpo = X_cleaned.drop('Transition', axis=1)\n",
    "    y = X_cleaned['Transition']\n",
    "    print(f\"Threshold: {threshold}, Features removed: {len(to_drop)}, Remaining features: {X_cleaned.shape[1]}\")\n",
    "    results = train_and_predict_Gradient_Boost(X_Limpo, y)\n",
    "    result_entry['F1_score_Gradient_Boost'] = results\n",
    "    print(\"\\n\\n\\n ##########################################\\n\\n\\n\")\n",
    "    \n",
    "    # ? ######### XGBOOST\n",
    "    X_cleaned, to_drop = remove_low_variance_features(data_XGBoost, threshold)\n",
    "    X_Limpo = X_cleaned.drop('Transition', axis=1)\n",
    "    y = X_cleaned['Transition']\n",
    "    print(f\"Threshold: {threshold}, Features removed: {len(to_drop)}, Remaining features: {X_cleaned.shape[1]}\")\n",
    "    results = train_and_predict_XGBOOST(X_Limpo, y)\n",
    "    result_entry['F1_score_XGBOOST'] = results\n",
    "    print(\"\\n\\n\\n ##########################################\\n\\n\\n\")\n",
    "    \n",
    "    # Adicionar o resultado consolidado\n",
    "    all_results.append(result_entry)\n",
    "\n",
    "# Comparar e imprimir os resultados no final\n",
    "print(\"\\nSummary of Results:\")\n",
    "for res in all_results:\n",
    "    print(f\"Threshold: {res['threshold']}, Features removed: {res['features_removed']}, \"\n",
    "          f\"Remaining features: {res['remaining_features']}, \"\n",
    "          f\"Random Forest: {res['F1_score_Random_Forest']}, \"\n",
    "          f\"Extra Trees: {res['F1_score_Extra_trees']}, \"\n",
    "          f\"Gradient Boost: {res['F1_score_Gradient_Boost']}, \"\n",
    "          f\"XGBoost: {res['F1_score_XGBOOST']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo           |   F1_Macro Original                |F1_Macro (0.001) | F1_Macro (0.002) | F1_Macro (0.003) | F1_Macro (0.004) | F1_Macro (0.005) |\n",
    "|------------------|-------------------|-----------------|------------------|------------------|------------------|------------------|\n",
    "| Random Forest    |    0.3800               |   0.3276        | 0.3037           | 0.3980           | 0.2766           | **0.4198**           |\n",
    "| Extra Trees      |     0.3707              |   0.3313        | 0.3168           | 0.2567           | 0.3076           | 0.2759           |\n",
    "| Gradient Boost   |      0.4097             |   0.4057        | 0.3644           | 0.3421           | 0.3642           | 0.3395           |\n",
    "| XGBoost          |  0.3705                 |   0.3478        | 0.3452           | 0.3196           | 0.3266           | 0.3214           |\n",
    "\n",
    "Apenas o Random Forest Demonstrou melhoria, por isso iremos continuar a testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing threshold: 0.006\n",
      "\n",
      "\n",
      "Threshold: 0.006, Features removed: 39, Remaining features: 346\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.79      0.66        24\n",
      "           1       0.57      0.53      0.55        15\n",
      "           2       0.30      0.35      0.32        17\n",
      "           3       0.33      0.17      0.22        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.35      0.37      0.35        77\n",
      "weighted avg       0.43      0.47      0.44        77\n",
      "\n",
      "F1_Macro: 0.35069\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.007\n",
      "\n",
      "\n",
      "Threshold: 0.007, Features removed: 44, Remaining features: 341\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.64        24\n",
      "           1       0.50      0.40      0.44        15\n",
      "           2       0.33      0.29      0.31        17\n",
      "           3       0.50      0.22      0.31        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.37      0.36      0.34        77\n",
      "weighted avg       0.44      0.47      0.43        77\n",
      "\n",
      "F1_Macro: 0.34020\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.008\n",
      "\n",
      "\n",
      "Threshold: 0.008, Features removed: 44, Remaining features: 341\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.64        24\n",
      "           1       0.50      0.40      0.44        15\n",
      "           2       0.33      0.29      0.31        17\n",
      "           3       0.50      0.22      0.31        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.47        77\n",
      "   macro avg       0.37      0.36      0.34        77\n",
      "weighted avg       0.44      0.47      0.43        77\n",
      "\n",
      "F1_Macro: 0.34020\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.009\n",
      "\n",
      "\n",
      "Threshold: 0.009, Features removed: 45, Remaining features: 340\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.83      0.63        24\n",
      "           1       0.62      0.53      0.57        15\n",
      "           2       0.47      0.47      0.47        17\n",
      "           3       0.25      0.11      0.15        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.49        77\n",
      "   macro avg       0.37      0.39      0.37        77\n",
      "weighted avg       0.44      0.49      0.45        77\n",
      "\n",
      "F1_Macro: 0.36616\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "Testing threshold: 0.01\n",
      "\n",
      "\n",
      "Threshold: 0.01, Features removed: 49, Remaining features: 336\n",
      "Model  (Random_Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69        24\n",
      "           1       0.55      0.40      0.46        15\n",
      "           2       0.24      0.24      0.24        17\n",
      "           3       0.33      0.17      0.22        18\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.45        77\n",
      "   macro avg       0.33      0.34      0.32        77\n",
      "weighted avg       0.41      0.45      0.41        77\n",
      "\n",
      "F1_Macro: 0.32131\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      " ##########################################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summary of Results:\n",
      "Threshold: 0.006, Features removed: 39, Remaining features: 346, Random Forest: 0.3506886196541369\n",
      "Threshold: 0.007, Features removed: 44, Remaining features: 341, Random Forest: 0.3402000777000777\n",
      "Threshold: 0.008, Features removed: 44, Remaining features: 341, Random Forest: 0.3402000777000777\n",
      "Threshold: 0.009, Features removed: 45, Remaining features: 340, Random Forest: 0.3661567190978955\n",
      "Threshold: 0.01, Features removed: 49, Remaining features: 336, Random Forest: 0.3213109602815486\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.006, 0.007, 0.008, 0.009, 0.01]\n",
    "all_results = []  # Lista para armazenar os resultados\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Testing threshold: {threshold}\\n\\n\")\n",
    "    \n",
    "    result_entry = {\n",
    "        'threshold': threshold,\n",
    "        'features_removed': None,  # Atualizado depois\n",
    "        'remaining_features': None,  # Atualizado depois\n",
    "        'F1_score_Random_Forest': None,\n",
    "        'F1_score_Extra_trees': None,\n",
    "        'F1_score_Gradient_Boost': None,\n",
    "        'F1_score_XGBOOST': None\n",
    "    }\n",
    "    \n",
    "    # ? ######### RANDOM_FOREST\n",
    "    X_cleaned, to_drop = remove_low_variance_features(data_Random_Forest, threshold)\n",
    "    X_Limpo = X_cleaned.drop('Transition', axis=1)\n",
    "    y = X_cleaned['Transition']\n",
    "    print(f\"Threshold: {threshold}, Features removed: {len(to_drop)}, Remaining features: {X_cleaned.shape[1]}\")\n",
    "    results = train_and_predict_random_forest(X_Limpo, y)\n",
    "    result_entry['F1_score_Random_Forest'] = results\n",
    "    result_entry['features_removed'] = len(to_drop)\n",
    "    result_entry['remaining_features'] = X_cleaned.shape[1]\n",
    "    print(\"\\n\\n\\n ##########################################\\n\\n\\n\")\n",
    "    \n",
    "\n",
    "    # Adicionar o resultado consolidado\n",
    "    all_results.append(result_entry)\n",
    "\n",
    "# Comparar e imprimir os resultados no final\n",
    "print(\"\\nSummary of Results:\")\n",
    "for res in all_results:\n",
    "    print(f\"Threshold: {res['threshold']}, Features removed: {res['features_removed']}, \"\n",
    "          f\"Remaining features: {res['remaining_features']}, \"\n",
    "          f\"Random Forest: {res['F1_score_Random_Forest']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nenhum Threshold melhorou mais a performance do random_forest, portanto para este modelo iremos adicionar o Threshold 0.005 no seu modelo de dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned, to_drop = remove_low_variance_features(data_Random_Forest, 0.005)\n",
    "\n",
    "X_cleaned.to_csv('2_data_Random_Forest_Clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
