{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        CN-CN\n",
      "1        CN-CN\n",
      "2        AD-AD\n",
      "3       CN-MCI\n",
      "4        CN-CN\n",
      "        ...   \n",
      "300      CN-CN\n",
      "301      CN-CN\n",
      "302     MCI-AD\n",
      "303    MCI-MCI\n",
      "304      CN-CN\n",
      "Name: Transition, Length: 305, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/RawData/train_radiomics_hipocamp.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/RawData/test_radiomics_hipocamp.csv')\n",
    "\n",
    "\n",
    "print(df['Transition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Value Colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.nunique() > 1]\n",
    "df_test = df_test.loc[:, df_test.nunique() > 1]\n",
    "\n",
    "#  Analise das colunas que tem menos de 50 valores unicos \n",
    "n = df.nunique()\n",
    "#for col, e in n.items():\n",
    "#    if e < 50:  \n",
    "#        print(f\"Coluna: {col}, Valores Unicos : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE BINING  ( secalhar isto era no 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_bins = [0, 65, 75, 85, 100]\n",
    "# BINS_SIZER = ['<65', '65-74', '75-84', '85+']\n",
    "age_labels = [60, 70, 80, 90] # VALOR MEDIO DO BIN \n",
    "df['Age'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "\n",
    "#print(df['Age'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colunas Categoricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar a contagem de valores únicos para cada coluna categórica\n",
    "\n",
    "# Identificar as colunas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "#for col in categorical_columns:\n",
    "#    print(f\"\\nColuna: {col}\")\n",
    "\n",
    "#colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash'] \n",
    "\n",
    "colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'] \n",
    "\n",
    "# ** Bounding Box\n",
    "#\n",
    "# ** as colunas do 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'\n",
    "# ** Deveriam ser retiradas, mas o bounding box pode ser importante para a zona de maior ativação do Alzimeir \n",
    "# **  ja a de centro de maxima devem ser muito correlacionados, por isso devem ser retirados mais para a frente \n",
    "# *TODO acabei por retirar para correr melhor os modelos, mas analisar se se deve retirar ou nao \n",
    "\n",
    "df.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)\n",
    "df_test.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar Transition CN-MCI \n",
    "\n",
    "Como este tipo de precisao não vai ser realiza, decidimos retirar todas as linhas com ela relacinadas para nao confundir o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Transition'] != 'CN-MCI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n",
    "\n",
    "# Apply the mapping to the target column\n",
    "#df['Transition'] = df['Transition'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#experiment = setup(df, target='Transition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o tratamento atual, o pycaret diz que os melhores modelos são :\n",
    "- Random Forest Classifier\n",
    "- Extra Trees Classifier\n",
    "- Gradient Boosting Classifier \n",
    "- K Neighbors Classifier\n",
    "- Extreme Gradient Boosting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos (default) ao dataset tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0        CN-CN\n",
      "1        CN-CN\n",
      "2        AD-AD\n",
      "3       CN-MCI\n",
      "4        CN-CN\n",
      "        ...   \n",
      "300      CN-CN\n",
      "301      CN-CN\n",
      "302     MCI-AD\n",
      "303    MCI-MCI\n",
      "304      CN-CN\n",
      "Name: Transition, Length: 305, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['Transition'].dtype)\n",
    "print(df['Transition'])\n",
    "\n",
    "df['Transition'] = df['Transition'].astype(str)\n",
    "\n",
    "df[['Origem', 'Destino']] = df['Transition'].str.split('-', expand=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro (Cross-Validation): 0.5168790952644908\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.56      0.38      0.45        24\n",
      "          CN       0.62      0.69      0.65        42\n",
      "         MCI       0.56      0.59      0.57        56\n",
      "\n",
      "    accuracy                           0.58       122\n",
      "   macro avg       0.58      0.55      0.56       122\n",
      "weighted avg       0.58      0.58      0.58       122\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'CN'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Criar e avaliar o modelo Random Forest para Destino\u001b[39;00m\n\u001b[1;32m     60\u001b[0m rf_destino_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m rf_score_destino \u001b[38;5;241m=\u001b[39m cross_val_score(rf_destino_model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Macro (Cross-Validation para Destino):\u001b[39m\u001b[38;5;124m\"\u001b[39m, rf_score_destino\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Treinar o modelo para prever o destino\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    725\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'CN'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Separar as features e os targets\n",
    "X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "y_origem = df['Origem']\n",
    "y_destino = df['Destino']\n",
    "y_transtion = df['Transition']\n",
    "# Dividir o conjunto de dados em treino e teste para validação\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_origem, test_size=0.40, random_state=34, stratify=y_origem)\n",
    "\n",
    "# Criar o modelo Random Forest\n",
    "rf_origem_model = RandomForestClassifier(n_estimators=800, random_state=34)\n",
    "\n",
    "\n",
    "# Avaliar desempenho com cross-validation no treino\n",
    "rf_score_origem = cross_val_score(rf_origem_model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"F1 Macro (Cross-Validation):\", rf_score_origem.mean())\n",
    "\n",
    "# Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "rf_origem_model.fit(X_train, y_train)\n",
    "rf_origem_pred = rf_origem_model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho no conjunto de teste\n",
    "print(\"Relatório de Classificação (Teste):\")\n",
    "print(classification_report(y_test, rf_origem_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "#cm = confusion_matrix(y_test, rf_origem_pred)\n",
    "#plot_confusion_matrix_with_labels(cm, label_mapping)\n",
    "\n",
    "# Prever para todo o dataset usando cross-validation (sem vazamento)\n",
    "df['Origem_Prevista'] = cross_val_predict(rf_origem_model, X, y_origem, cv=5)\n",
    "\n",
    "# Adicionar Origem_Prevista como feature para Destino\n",
    "X_destino = X.copy()\n",
    "X_destino['Origem_Prevista'] = df['Origem_Prevista']\n",
    "\n",
    "label_origem_encoding = {\n",
    "    'CN': 0,\n",
    "    'AD': 1,\n",
    "    'MCI': 2,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "X_destino['Origem_Prevista'] = X_destino['Origem_Prevista'].map(label_origem_encoding)\n",
    "\n",
    "\n",
    "# Dividir o conjunto de dados para prever o destino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_destino, y_destino, test_size=0.40, random_state=34, stratify=y_destino)\n",
    "\n",
    "# Criar e avaliar o modelo Random Forest para Destino\n",
    "rf_destino_model = RandomForestClassifier(n_estimators=800, random_state=34)\n",
    "rf_score_destino = cross_val_score(rf_destino_model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"F1 Macro (Cross-Validation para Destino):\", rf_score_destino.mean())\n",
    "\n",
    "# Treinar o modelo para prever o destino\n",
    "rf_destino_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer predições no conjunto de teste\n",
    "rf_destino_pred = rf_destino_model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho no conjunto de teste\n",
    "print(\"Relatório de Classificação (Destino):\")\n",
    "print(classification_report(y_test, rf_destino_pred))\n",
    "\n",
    "# Matriz de confusão para o destino\n",
    "#cm_destino = confusion_matrix(y_test, rf_destino_pred)\n",
    "#plot_confusion_matrix_with_labels(cm_destino, label_mapping)\n",
    "\n",
    "# Prever o destino para todo o dataset usando cross-validation\n",
    "df['Destino_Previsto'] = cross_val_predict(rf_destino_model, X_destino, y_destino, cv=5)\n",
    "\n",
    "# Exibir as predições completas\n",
    "print(df[['Origem', 'Origem_Prevista', 'Destino', 'Destino_Previsto']].head())\n",
    "\n",
    "\n",
    "\n",
    "## Normalizar os dados usando StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "## Ajustar o scaler apenas nos dados de treino e transformar os dados de treino e teste\n",
    "#X_train_normalizado = scaler.fit_transform(X_train)\n",
    "#X_test_normalizado = scaler.transform(X_test)\n",
    "\n",
    "# Exibir formas e primeiras linhas dos dados normalizados\n",
    "\n",
    "\n",
    "# Inicializar dicionário para armazenar as pontuações de cross-validation do modelo\n",
    "model_cross_score = {}\n",
    "z1_score = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def avaliar_modelos(df, modelo_origem_class, modelo_destino_class, \n",
    "                    params_origem=None, params_destino=None, \n",
    "                    label_mapping_origem=None, label_mapping_destino=None):\n",
    "    \"\"\"\n",
    "    Avalia modelos de machine learning para Origem e Destino, com construção dinâmica dos modelos.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame contendo as colunas 'Origem', 'Destino', 'Transition' e as features.\n",
    "    - modelo_origem_class: Classe do modelo a ser usado para prever Origem (ex.: RandomForestClassifier).\n",
    "    - modelo_destino_class: Classe do modelo a ser usado para prever Destino (ex.: XGBClassifier).\n",
    "    - params_origem: Dicionário de parâmetros para o modelo de Origem.\n",
    "    - params_destino: Dicionário de parâmetros para o modelo de Destino.\n",
    "    - label_mapping_origem: Dicionário para mapear Origem_Prevista (opcional).\n",
    "    - label_mapping_destino: Dicionário para mapear Destino_Previsto (opcional).\n",
    "    \n",
    "    Retorna:\n",
    "    - Um dicionário com:\n",
    "        - F1-scores para Origem e Destino.\n",
    "        - Matrizes de confusão para Origem e Destino.\n",
    "    \"\"\"\n",
    "    # Inicializar parâmetros, se não fornecidos\n",
    "    params_origem = params_origem or {}\n",
    "    params_destino = params_destino or {}\n",
    "\n",
    "    # Criar os modelos dinamicamente\n",
    "    modelo_origem = modelo_origem_class(**params_origem)\n",
    "    modelo_destino = modelo_destino_class(**params_destino)\n",
    "\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_origem = y_origem.map(label_mapping_origem)\n",
    "    print(y_origem)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_origem, test_size=0.40, random_state=34, stratify=y_origem)\n",
    "\n",
    "    score_origem = cross_val_score(modelo_origem, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "\n",
    "    df['Origem_Prevista'] = score_origem\n",
    "\n",
    "    modelo_origem.fit(X_train, y_train)\n",
    "    origem_pred = modelo_origem.predict(X_test)\n",
    "\n",
    "    # Avaliar o desempenho para Origem\n",
    "\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test, rf_origem_pred))\n",
    "\n",
    "    # Adicionar 'Origem_Prevista' como feature para Destino\n",
    "    X_destino = X.copy()\n",
    "    if label_mapping_destino:\n",
    "        df['Origem_Prevista'] = df['Origem_Prevista'].map(label_mapping_origem)\n",
    "    X_destino['Origem_Prevista'] = df['Origem_Prevista']\n",
    "\n",
    "    # Previsão para Destino usando cross-validation\n",
    "    df['Destino_Previsto'] = cross_val_predict(modelo_destino, X_destino, y_destino, cv=5)\n",
    "\n",
    "    # Avaliar o desempenho para Destino\n",
    "    f1_destino = f1_score(y_destino, df['Destino_Previsto'], average='macro')\n",
    "    cm_destino = confusion_matrix(y_destino, df['Destino_Previsto'])\n",
    "\n",
    "    # Resultado consolidado\n",
    "    resultado = {\n",
    "        \"F1 Origem\": f1_origem,\n",
    "        \"F1 Destino\": f1_destino,\n",
    "        \"Matriz de Confusão Origem\": cm_origem,\n",
    "        \"Matriz de Confusão Destino\": cm_destino,\n",
    "    }\n",
    "\n",
    "    return resultado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = avaliar_modelos(\n",
    "    df,\n",
    "    modelo_origem_class=RandomForestClassifier,\n",
    "    modelo_destino_class=RandomForestClassifier,\n",
    "    params_origem={'n_estimators': 800, 'random_state': 34},\n",
    "    params_destino={'n_estimators': 800, 'random_state': 34},\n",
    "    label_mapping_origem={'CN': 0, 'AD': 1, 'MCI': 2},\n",
    "    label_mapping_destino={'CN': 0, 'AD': 1, 'MCI': 2}\n",
    ")\n",
    "\n",
    "print(\"F1 Score Origem:\", resultados[\"F1 Origem\"])\n",
    "print(\"F1 Score Destino:\", resultados[\"F1 Destino\"])\n",
    "print(\"Matriz de Confusão Origem:\\n\", resultados[\"Matriz de Confusão Origem\"])\n",
    "print(\"Matriz de Confusão Destino:\\n\", resultados[\"Matriz de Confusão Destino\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
