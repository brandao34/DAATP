{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/Data/5. Data APOS 1_2 sem desvio padrao.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/process/Main_Versao/Com CN-MCI/Processamento/DF_Test_1_After_Pre_Processamento.csv')\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao Axuliar: Matrix de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devisão Origem e Destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      2\n",
      "      ..\n",
      "290    0\n",
      "291    0\n",
      "292    2\n",
      "293    3\n",
      "294    0\n",
      "Name: Transition, Length: 295, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Transition'].dtype)\n",
    "print(df['Transition'])\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n",
    "# Criar o dicionário de reverse mapping\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Aplicar o reverse mapping à coluna Transition\n",
    "df['Transition'] = df['Transition'].map(reverse_label_mapping)\n",
    "\n",
    "df['Transition'] = df['Transition'].astype(str)\n",
    "\n",
    "df[['Origem', 'Destino']] = df['Transition'].str.split('-', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_transition_previsao(row, stats):\n",
    "    # Combinações válidas\n",
    "    combinacoes_validas = {'CN-CN', 'AD-AD', 'MCI-AD', 'MCI-MCI', 'CN-MCI'}\n",
    "\n",
    "    # Criar a combinação da origem e destino previstos\n",
    "    transition = f\"{row['Origem_Prevista']}-{row['Destino_Prevista']}\"\n",
    "\n",
    "    # Verificar se a combinação é válida\n",
    "    if transition in combinacoes_validas:\n",
    "        return transition\n",
    "    else:\n",
    "        # Regras para combinações inválidas\n",
    "        if row['Destino_Prevista'] == 'MCI' and row['Origem_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        elif row['Origem_Prevista'] == 'CN' and row['Destino_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'CN-MCI'\n",
    "        elif row['Origem_Prevista'] == 'AD' and row['Destino_Prevista'] != 'AD':\n",
    "            stats['alterados'] += 1\n",
    "            return 'AD-AD'\n",
    "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        else:\n",
    "            # Contar os casos que não foram corrigidos por falta de regra\n",
    "            stats['nao_corrigidos'] += 1\n",
    "            return transition  # Retorna o original, mesmo que inválido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_origem(df, modelo_origem): \n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transtion = df['Transition']\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "\n",
    "    # Divisão principal para garantir que os índices de teste sejam os mesmos\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transtion, test_size=0.40, random_state=34, stratify=y_transtion\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem[X_train_transition.index], y_origem[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino[X_train_transition.index], y_destino[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    #\n",
    "\n",
    "\n",
    "    # ? ORIGEM #########################################################\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_origem_model = modelo_origem\n",
    "    # Avaliar desempenho com cross-validation no treino\n",
    "    rf_score_origem = cross_val_score(rf_origem_model, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    #print(\"F1 Macro (Cross-Validation):\", rf_score_origem.mean())\n",
    "    # Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "    rf_origem_model.fit(X_train_origem, y_train_origem)\n",
    "    rf_origem_pred = rf_origem_model.predict(X_test_origem)\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "   # print(\"Relatório de Classificação (Teste):\")\n",
    "   # print(classification_report(y_test_origem, rf_origem_pred))\n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_origem, \n",
    "    rf_origem_pred,    output_dict=True)\n",
    "\n",
    "\n",
    "    return report_dict, rf_score_origem.mean(), rf_score_origem.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def processar_destino_com_label_encoder(df, modelo_destino):\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transition = df['Transition']\n",
    "\n",
    "    # Codificar as classes para y_origem, y_destino e y_transition\n",
    "    label_encoder_origem = LabelEncoder()\n",
    "    y_origem_encoded = label_encoder_origem.fit_transform(y_origem)\n",
    "\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "    y_destino_encoded = label_encoder_destino.fit_transform(y_destino)\n",
    "\n",
    "    label_encoder_transition = LabelEncoder()\n",
    "    y_transition_encoded = label_encoder_transition.fit_transform(y_transition)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transition_encoded, test_size=0.40, random_state=34, stratify=y_transition_encoded\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem_encoded[X_train_transition.index], y_origem_encoded[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino_encoded[X_train_transition.index], y_destino_encoded[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "\n",
    "    # Treinar e avaliar o modelo de Origem\n",
    "    rf_score_destino = cross_val_score(modelo_destino, X_train_destino, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    #print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_origem.mean())\n",
    "    #print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_origem.std())\n",
    "\n",
    "    modelo_destino.fit(X_train_destino, y_train_destino)\n",
    "    destino_pred = modelo_destino.predict(X_test_destino)\n",
    "    destino_pred_test = modelo_destino.predict(X_test_transition)\n",
    "\n",
    "   \n",
    "\n",
    "    #print(\"Relatório de Classificação (Teste):\")\n",
    "    \n",
    "    #print(classification_report(y_test_origem, origem_pred, target_names=label_encoder_origem.classes_ ))\n",
    "    \n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_destino, \n",
    "    destino_pred_test, \n",
    "    output_dict=True, target_names=label_encoder_origem.classes_)\n",
    "    return  report_dict , rf_score_destino.mean(),  rf_score_destino.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados Resumidos:\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|    | Modelo           |   F1 Macro (Score Médio) |   F1 Macro (Desvio Padrão) |\n",
      "+====+==================+==========================+============================+\n",
      "|  0 | ExtraTrees       |                 0.482943 |                  0.045026  |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  1 | RandomForest     |                 0.465133 |                  0.0527457 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  2 | GradientBoosting |                 0.453584 |                  0.0768293 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  3 | KNeighbors       |                 0.394377 |                  0.0725168 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  4 | SVC              |                 0.38086  |                  0.0375559 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  5 | XGBOOST          |                 0.441785 |                  0.0512871 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "\n",
      "Classification Reports:\n",
      "\n",
      "ExtraTrees - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.636364  0.823529  0.717949   51.000000\n",
      "CN             0.607843  0.794872  0.688889   39.000000\n",
      "MCI            1.000000  0.035714  0.068966   28.000000\n",
      "accuracy       0.627119  0.627119  0.627119    0.627119\n",
      "macro avg      0.748069  0.551372  0.491934  118.000000\n",
      "weighted avg   0.713224  0.627119  0.554348  118.000000\n",
      "\n",
      "RandomForest - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.646154  0.823529  0.724138   51.000000\n",
      "CN             0.627451  0.820513  0.711111   39.000000\n",
      "MCI            0.500000  0.035714  0.066667   28.000000\n",
      "accuracy       0.635593  0.635593  0.635593    0.635593\n",
      "macro avg      0.591202  0.559919  0.500639  118.000000\n",
      "weighted avg   0.605292  0.635593  0.563822  118.000000\n",
      "\n",
      "GradientBoosting - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.701754  0.784314  0.740741   51.000000\n",
      "CN             0.591837  0.743590  0.659091   39.000000\n",
      "MCI            0.500000  0.214286  0.300000   28.000000\n",
      "accuracy       0.635593  0.635593  0.635593    0.635593\n",
      "macro avg      0.597864  0.580730  0.566611  118.000000\n",
      "weighted avg   0.617552  0.635593  0.609172  118.000000\n",
      "\n",
      "KNeighbors - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.545455  0.705882  0.615385   51.000000\n",
      "CN             0.487805  0.512821  0.500000   39.000000\n",
      "MCI            0.454545  0.178571  0.256410   28.000000\n",
      "accuracy       0.516949  0.516949  0.516949    0.516949\n",
      "macro avg      0.495935  0.465758  0.457265  118.000000\n",
      "weighted avg   0.504829  0.516949  0.492069  118.000000\n",
      "\n",
      "SVC - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.500000  0.803922  0.616541   51.000000\n",
      "CN             0.527778  0.487179  0.506667   39.000000\n",
      "MCI            0.000000  0.000000  0.000000   28.000000\n",
      "accuracy       0.508475  0.508475  0.508475    0.508475\n",
      "macro avg      0.342593  0.430367  0.374403  118.000000\n",
      "weighted avg   0.390537  0.508475  0.433929  118.000000\n",
      "\n",
      "XGBOOST - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.711864  0.823529  0.763636   51.000000\n",
      "CN             0.620000  0.794872  0.696629   39.000000\n",
      "MCI            0.555556  0.178571  0.270270   28.000000\n",
      "accuracy       0.661017  0.661017  0.661017    0.661017\n",
      "macro avg      0.629140  0.598991  0.576845  118.000000\n",
      "weighted avg   0.644412  0.661017  0.624420  118.000000\n",
      "\n",
      "Top 3 Models based on F1 Macro Score for AD, CN, and MCI:\n",
      "1. XGBOOST - F1 (AD): 0.7636, F1 (CN): 0.6966, F1 (MCI): 0.2703\n",
      "2. GradientBoosting - F1 (AD): 0.7407, F1 (CN): 0.6591, F1 (MCI): 0.3000\n",
      "3. RandomForest - F1 (AD): 0.7241, F1 (CN): 0.7111, F1 (MCI): 0.0667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Modelos\n",
    "modelos = {\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=447, max_features='sqrt', max_depth=15,\n",
    "        min_samples_split=10, min_samples_leaf=5, bootstrap=False, random_state=34\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=151, max_features='log2', max_depth=13,\n",
    "        min_samples_split=10, min_samples_leaf=3, bootstrap=True, random_state=34\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        learning_rate=0.1, n_estimators=100, random_state=34\n",
    "    ),\n",
    "    \"KNeighbors\": KNeighborsClassifier(\n",
    "        n_neighbors=5, weights='uniform', algorithm='auto'\n",
    "    ),\n",
    "    \"SVC\": SVC(\n",
    "        kernel='rbf', random_state=34\n",
    "    ),\n",
    "    \"XGBOOST\" : XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "}\n",
    "\n",
    "# Avaliação dos modelos e armazenamento dos resultados\n",
    "resultados = []\n",
    "classification_reports = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    # Chamar a função de processamento\n",
    "    report, f1_macro_score, f1_macro_std = processar_destino_com_label_encoder(df, modelo)\n",
    "    resultados.append({\n",
    "        \"Modelo\": nome,\n",
    "        \"F1 Macro (Score Médio)\": f1_macro_score,\n",
    "        \"F1 Macro (Desvio Padrão)\": f1_macro_std\n",
    "    })\n",
    "    \n",
    "    # Armazenar o classification report para exibição posterior\n",
    "    classification_reports[nome] = report\n",
    "\n",
    "# Converter resultados em tabela\n",
    "tabela_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Exibir tabela formatada\n",
    "print(\"\\nResultados Resumidos:\")\n",
    "print(tabulate(tabela_resultados, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "# Criar uma lista para armazenar os resultados de F1 macro para os três parâmetros\n",
    "f1_scores = []\n",
    "\n",
    "# Exibir classification reports de todos os modelos\n",
    "print(\"\\nClassification Reports:\")\n",
    "for nome, report in classification_reports.items():\n",
    "    print(f\"\\n{nome} - Classification Report\")\n",
    "    df_report = pd.DataFrame(report).transpose()  # Mostrar o report como DataFrame para facilitar leitura\n",
    "    print(df_report)\n",
    "\n",
    "    # Extrair os valores de F1 macro para AD, CN e MCI\n",
    "    f1_ad = report.get('AD', {}).get('f1-score', 0)\n",
    "    f1_cn = report.get('CN', {}).get('f1-score', 0)\n",
    "    f1_mci = report.get('MCI', {}).get('f1-score', 0)\n",
    "\n",
    "    # Armazenar os valores e o nome do modelo\n",
    "    f1_scores.append((nome, f1_ad, f1_cn, f1_mci))\n",
    "\n",
    "# Ordenar os modelos com base no F1 macro (média dos três parâmetros)\n",
    "f1_scores_sorted = sorted(f1_scores, key=lambda x: (x[1] + x[2] + x[3]) / 3, reverse=True)\n",
    "\n",
    "# Exibir os três melhores modelos com suas respectivas pontuações F1 macro\n",
    "print(\"\\nTop 3 Models based on F1 Macro Score for AD, CN, and MCI:\")\n",
    "for i, (nome, f1_ad, f1_cn, f1_mci) in enumerate(f1_scores_sorted[:3], 1):\n",
    "    print(f\"{i}. {nome} - F1 (AD): {f1_ad:.4f}, F1 (CN): {f1_cn:.4f}, F1 (MCI): {f1_mci:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost:\n",
      "{'AD': {'precision': 0.711864406779661, 'recall': 0.8235294117647058, 'f1-score': 0.7636363636363637, 'support': 51.0}, 'CN': {'precision': 0.62, 'recall': 0.7948717948717948, 'f1-score': 0.6966292134831461, 'support': 39.0}, 'MCI': {'precision': 0.5555555555555556, 'recall': 0.17857142857142858, 'f1-score': 0.2702702702702703, 'support': 28.0}, 'accuracy': 0.6610169491525424, 'macro avg': {'precision': 0.6291399874450722, 'recall': 0.5989908784026431, 'f1-score': 0.57684528246326, 'support': 118.0}, 'weighted avg': {'precision': 0.6444122059433751, 'recall': 0.6610169491525424, 'f1-score': 0.6244200121937695, 'support': 118.0}}\n",
      "F1_macro_Score:\n",
      "0.44178512534132686\n",
      "F1_macro_Desvio_padrao:\n",
      "0.0512870761142803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar instâncias dos modelos\n",
    "xgbost_origem = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "\n",
    "random_forest_origem = RandomForestClassifier(n_estimators=800,random_state=34)\n",
    "\n",
    "\n",
    "report_xgboost, f1_macro_score_xgboost, f1_macro_std_xgboost = processar_destino_com_label_encoder(df,xgbost_origem)\n",
    "report_random, f1_macro_score_rf, f1_macro_std_rf = gerar_origem(df,random_forest_origem)\n",
    "\n",
    "print(\"Xgboost:\")\n",
    "print(report_xgboost)\n",
    "print(\"F1_macro_Score:\")\n",
    "print(f1_macro_score_xgboost)\n",
    "print(\"F1_macro_Desvio_padrao:\")\n",
    "print(f1_macro_std_xgboost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
