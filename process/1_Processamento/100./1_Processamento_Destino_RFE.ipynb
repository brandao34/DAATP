{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/process/Main_Versao/Com CN-MCI/Processamento/DF_CN-MCI_1_After_Pre_Processamento.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/process/Main_Versao/Com CN-MCI/Processamento/DF_Test_1_After_Pre_Processamento.csv')\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao Axuliar: Matrix de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devisão Origem e Destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      4\n",
      "4      0\n",
      "      ..\n",
      "300    0\n",
      "301    0\n",
      "302    2\n",
      "303    3\n",
      "304    0\n",
      "Name: Transition, Length: 305, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Transition'].dtype)\n",
    "print(df['Transition'])\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n",
    "# Criar o dicionário de reverse mapping\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Aplicar o reverse mapping à coluna Transition\n",
    "df['Transition'] = df['Transition'].map(reverse_label_mapping)\n",
    "\n",
    "df['Transition'] = df['Transition'].astype(str)\n",
    "\n",
    "df[['Origem', 'Destino']] = df['Transition'].str.split('-', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_transition_previsao(row, stats):\n",
    "    # Combinações válidas\n",
    "    combinacoes_validas = {'CN-CN', 'AD-AD', 'MCI-AD', 'MCI-MCI', 'CN-MCI'}\n",
    "\n",
    "    # Criar a combinação da origem e destino previstos\n",
    "    transition = f\"{row['Origem_Prevista']}-{row['Destino_Prevista']}\"\n",
    "\n",
    "    # Verificar se a combinação é válida\n",
    "    if transition in combinacoes_validas:\n",
    "        return transition\n",
    "    else:\n",
    "        # Regras para combinações inválidas\n",
    "        if row['Destino_Prevista'] == 'MCI' and row['Origem_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        elif row['Origem_Prevista'] == 'CN' and row['Destino_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'CN-MCI'\n",
    "        elif row['Origem_Prevista'] == 'AD' and row['Destino_Prevista'] != 'AD':\n",
    "            stats['alterados'] += 1\n",
    "            return 'AD-AD'\n",
    "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        else:\n",
    "            # Contar os casos que não foram corrigidos por falta de regra\n",
    "            stats['nao_corrigidos'] += 1\n",
    "            return transition  # Retorna o original, mesmo que inválido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_origem(df, modelo_origem): \n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transtion = df['Transition']\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "\n",
    "    # Divisão principal para garantir que os índices de teste sejam os mesmos\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transtion, test_size=0.40, random_state=34, stratify=y_transtion\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem[X_train_transition.index], y_origem[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    #\n",
    "\n",
    "\n",
    "    # ? ORIGEM #########################################################\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_origem_model = modelo_origem\n",
    "    # Avaliar desempenho com cross-validation no treino\n",
    "    rf_score_origem = cross_val_score(rf_origem_model, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    #print(\"F1 Macro (Cross-Validation):\", rf_score_origem.mean())\n",
    "    # Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "    rf_origem_model.fit(X_train_origem, y_train_origem)\n",
    "    rf_origem_pred = rf_origem_model.predict(X_test_origem)\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_origem, rf_origem_pred))\n",
    "\n",
    "    \n",
    "    selector = SelectFromModel(estimator=RandomForestClassifier(n_estimators=800, random_state=42), threshold=\"median\")\n",
    "    X_train_reduzido = selector.fit_transform(X_train_origem, y_train_origem)\n",
    "    X_test_reduzido = selector.transform(X_test_origem)\n",
    "    print(X_train_origem.shape)\n",
    "    print(X_train_reduzido.shape)\n",
    "    modelo_reduzido = RandomForestClassifier(random_state=42, n_estimators=800)\n",
    "    modelo_reduzido.fit(X_train_reduzido, y_train_origem)\n",
    "    y_pred_reduzido = modelo_reduzido.predict(X_test_reduzido)\n",
    "\n",
    "    print(\"\\nRelatório com Seleção Automática de Features:\")\n",
    "    print(classification_report(y_test_origem, y_pred_reduzido))\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_origem, \n",
    "    rf_origem_pred,    output_dict=True)\n",
    "\n",
    "\n",
    "    return report_dict, rf_score_origem.mean(), rf_score_origem.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def processar_transicoes_com_label_encoder(df, modelo_destino):\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transition = df['Transition']\n",
    "\n",
    "\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "    y_destino_encoded = label_encoder_destino.fit_transform(y_destino)\n",
    "\n",
    "    label_encoder_transition = LabelEncoder()\n",
    "    y_transition_encoded = label_encoder_transition.fit_transform(y_transition)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transition_encoded, test_size=0.40, random_state=34, stratify=y_transition_encoded\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_destino, y_test_destino = y_destino_encoded[X_train_transition.index], y_destino_encoded[X_test_transition.index]\n",
    "\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    modelo_destino.fit(X_train_destino, y_train_destino)\n",
    "    destino_pred = modelo_destino.predict(X_test_destino)\n",
    "    destino_pred_test = modelo_destino.predict(X_test_transition)\n",
    "\n",
    "\n",
    "       # Avaliar o desempenho no conjunto de teste\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_destino, destino_pred_test))\n",
    "\n",
    "\n",
    "    rf_score_destino= cross_val_score(modelo_destino, X_train_destino, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_destino.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_destino.std())\n",
    "    \n",
    "  \n",
    "    # Aplicar SelectFromModel para reduzir as features\n",
    "    selector = SelectFromModel(modelo_destino, threshold=\"median\")\n",
    "    X_train_reduzido = selector.fit_transform(X_train_destino, y_train_destino)\n",
    "    X_test_reduzido = selector.transform(X_test_destino)\n",
    "    \n",
    "    # Exibir as dimensões antes e depois da redução\n",
    "    print(\"Dimensão original:\", X_train_destino.shape)\n",
    "    print(\"Dimensão reduzida:\", X_train_reduzido.shape)\n",
    "    \n",
    "    # Treinar o modelo com as features reduzidas\n",
    "    modelo_reduzido =modelo_destino\n",
    "    modelo_reduzido.fit(X_train_reduzido, y_train_destino)\n",
    "    y_pred_reduzido = modelo_reduzido.predict(X_test_reduzido)\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    print(\"\\nRelatório com Seleção Automática de Features:\")\n",
    "    print(classification_report(y_test_destino, y_pred_reduzido))\n",
    "    \n",
    "    # Obter as colunas selecionadas pelo SelectFromModel\n",
    "    mask = selector.get_support()  # Máscara booleana indicando as colunas selecionadas\n",
    "    colunas_selecionadas = X_train_destino.columns[mask]\n",
    "    colunas_removidas = X_train_destino.columns[~mask]\n",
    "    rf_score_reduzido= cross_val_score(modelo_reduzido, X_train_reduzido, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_reduzido.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_reduzido.std())\n",
    "    \n",
    "    # Salvar as colunas removidas em um arquivo CSV\n",
    "    colunas_removidas_df = pd.DataFrame({'Features Removidas': colunas_removidas})\n",
    "    colunas_removidas_df.to_csv('colunas_removidas_destino.csv', index=False)\n",
    "    \n",
    "    print(f\"Lista de {len(colunas_removidas)} colunas removidas salva em 'colunas_removidas.csv'\")\n",
    "    \n",
    "    #print(classification_report(y_test_origem, origem_pred, target_names=label_encoder_origem.classes_ ))\n",
    "    \n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_destino, \n",
    "    destino_pred_test, \n",
    "    output_dict=True, target_names=label_encoder_destino.classes_)\n",
    "    return  report_dict , rf_score_destino.mean(),  rf_score_destino.std(), destino_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ExtraTrees\n",
      "\n",
      "\n",
      "\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74        51\n",
      "           1       0.54      0.79      0.64        38\n",
      "           2       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.59       122\n",
      "   macro avg       0.40      0.54      0.46       122\n",
      "weighted avg       0.45      0.59      0.51       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.4694289704485783\n",
      "Desvio Padrão F1 Macro (Origem): 0.04431703103138058\n",
      "Dimensão original: (183, 2013)\n",
      "Dimensão reduzida: (183, 1007)\n",
      "\n",
      "Relatório com Seleção Automática de Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76        51\n",
      "           1       0.56      0.84      0.67        38\n",
      "           2       0.60      0.09      0.16        33\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.62      0.59      0.53       122\n",
      "weighted avg       0.63      0.63      0.57       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.5049658881423589\n",
      "Desvio Padrão F1 Macro (Origem): 0.04179065265085178\n",
      "Lista de 1006 colunas removidas salva em 'colunas_removidas.csv'\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "\n",
      "\n",
      "\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76        51\n",
      "           1       0.56      0.79      0.65        38\n",
      "           2       0.45      0.15      0.23        33\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.58      0.58      0.55       122\n",
      "weighted avg       0.60      0.62      0.58       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.4818279741201943\n",
      "Desvio Padrão F1 Macro (Origem): 0.05210212431034812\n",
      "Dimensão original: (183, 2013)\n",
      "Dimensão reduzida: (183, 1007)\n",
      "\n",
      "Relatório com Seleção Automática de Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77        51\n",
      "           1       0.55      0.76      0.64        38\n",
      "           2       0.44      0.12      0.19        33\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.57      0.58      0.53       122\n",
      "weighted avg       0.59      0.62      0.57       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.4718130841733383\n",
      "Desvio Padrão F1 Macro (Origem): 0.06445252260653568\n",
      "Lista de 1006 colunas removidas salva em 'colunas_removidas.csv'\n",
      "\n",
      "\n",
      "\n",
      "GradientBoosting\n",
      "\n",
      "\n",
      "\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        51\n",
      "           1       0.59      0.76      0.67        38\n",
      "           2       0.37      0.21      0.27        33\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.55      0.57      0.55       122\n",
      "weighted avg       0.58      0.61      0.58       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.49492547421400557\n",
      "Desvio Padrão F1 Macro (Origem): 0.06206160842703151\n",
      "Dimensão original: (183, 2013)\n",
      "Dimensão reduzida: (183, 2013)\n",
      "\n",
      "Relatório com Seleção Automática de Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        51\n",
      "           1       0.59      0.76      0.67        38\n",
      "           2       0.37      0.21      0.27        33\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.55      0.57      0.55       122\n",
      "weighted avg       0.58      0.61      0.58       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.49492547421400557\n",
      "Desvio Padrão F1 Macro (Origem): 0.06206160842703151\n",
      "Lista de 0 colunas removidas salva em 'colunas_removidas.csv'\n",
      "\n",
      "\n",
      "\n",
      "XGBOOST\n",
      "\n",
      "\n",
      "\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        51\n",
      "           1       0.57      0.79      0.66        38\n",
      "           2       0.40      0.18      0.25        33\n",
      "\n",
      "    accuracy                           0.63       122\n",
      "   macro avg       0.58      0.59      0.56       122\n",
      "weighted avg       0.60      0.63      0.60       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.4564894886677323\n",
      "Desvio Padrão F1 Macro (Origem): 0.05697337584927931\n",
      "Dimensão original: (183, 2013)\n",
      "Dimensão reduzida: (183, 1007)\n",
      "\n",
      "Relatório com Seleção Automática de Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        51\n",
      "           1       0.55      0.82      0.66        38\n",
      "           2       0.33      0.12      0.18        33\n",
      "\n",
      "    accuracy                           0.61       122\n",
      "   macro avg       0.54      0.57      0.53       122\n",
      "weighted avg       0.57      0.61      0.57       122\n",
      "\n",
      "F1 Macro (Cross-Validation - Origem): 0.4732974500003486\n",
      "Desvio Padrão F1 Macro (Origem): 0.0525266338272446\n",
      "Lista de 1006 colunas removidas salva em 'colunas_removidas.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar instâncias dos modelos\n",
    "xgbost_origem = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "\n",
    "random_forest_origem = RandomForestClassifier(n_estimators=800,random_state=34)\n",
    "\n",
    "\n",
    "#report_xgboost, f1_macro_score_xgboost, f1_macro_std_xgboost = processar_transicoes_com_label_encoder(df,xgbost_origem)\n",
    "#report_random, f1_macro_score_rf, f1_macro_std_rf = gerar_origem(df,random_forest_origem)\n",
    "\n",
    "modelos = {\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=447, max_features='sqrt', max_depth=15,\n",
    "        min_samples_split=10, min_samples_leaf=5, bootstrap=False, random_state=34\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=151, max_features='log2', max_depth=13,\n",
    "        min_samples_split=10, min_samples_leaf=3, bootstrap=True, random_state=34\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        learning_rate=0.1, n_estimators=100, random_state=34\n",
    "    ),\n",
    "    \"XGBOOST\" : XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "}\n",
    "\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    # Chamar a função de processamento\n",
    "    print(\"\\n\\n\")\n",
    "    print(nome)\n",
    "    print(\"\\n\\n\")\n",
    "    report, f1_macro_score, f1_macro_std, previsoes_orgiem = processar_transicoes_com_label_encoder(df, modelo)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
