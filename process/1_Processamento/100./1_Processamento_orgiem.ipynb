{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/process/Main_Versao/Com CN-MCI/Processamento/DF_CN-MCI_1_After_Pre_Processamento.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/process/Main_Versao/Com CN-MCI/Processamento/DF_Test_1_After_Pre_Processamento.csv')\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao Axuliar: Matrix de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devisão Origem e Destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      4\n",
      "4      0\n",
      "      ..\n",
      "300    0\n",
      "301    0\n",
      "302    2\n",
      "303    3\n",
      "304    0\n",
      "Name: Transition, Length: 305, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Transition'].dtype)\n",
    "print(df['Transition'])\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n",
    "# Criar o dicionário de reverse mapping\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Aplicar o reverse mapping à coluna Transition\n",
    "df['Transition'] = df['Transition'].map(reverse_label_mapping)\n",
    "\n",
    "df['Transition'] = df['Transition'].astype(str)\n",
    "\n",
    "df[['Origem', 'Destino']] = df['Transition'].str.split('-', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_transition_previsao(row, stats):\n",
    "    # Combinações válidas\n",
    "    combinacoes_validas = {'CN-CN', 'AD-AD', 'MCI-AD', 'MCI-MCI', 'CN-MCI'}\n",
    "\n",
    "    # Criar a combinação da origem e destino previstos\n",
    "    transition = f\"{row['Origem_Prevista']}-{row['Destino_Prevista']}\"\n",
    "\n",
    "    # Verificar se a combinação é válida\n",
    "    if transition in combinacoes_validas:\n",
    "        return transition\n",
    "    else:\n",
    "        # Regras para combinações inválidas\n",
    "        if row['Destino_Prevista'] == 'MCI' and row['Origem_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        elif row['Origem_Prevista'] == 'CN' and row['Destino_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'CN-MCI'\n",
    "        elif row['Origem_Prevista'] == 'AD' and row['Destino_Prevista'] != 'AD':\n",
    "            stats['alterados'] += 1\n",
    "            return 'AD-AD'\n",
    "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
    "            stats['alterados'] += 1\n",
    "            return 'MCI-MCI'\n",
    "        else:\n",
    "            # Contar os casos que não foram corrigidos por falta de regra\n",
    "            stats['nao_corrigidos'] += 1\n",
    "            return transition  # Retorna o original, mesmo que inválido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_origem(df, modelo_origem): \n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transtion = df['Transition']\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "\n",
    "    # Divisão principal para garantir que os índices de teste sejam os mesmos\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transtion, test_size=0.40, random_state=34, stratify=y_transtion\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem[X_train_transition.index], y_origem[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino[X_train_transition.index], y_destino[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    #\n",
    "\n",
    "\n",
    "    # ? ORIGEM #########################################################\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_origem_model = modelo_origem\n",
    "    # Avaliar desempenho com cross-validation no treino\n",
    "    rf_score_origem = cross_val_score(rf_origem_model, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    #print(\"F1 Macro (Cross-Validation):\", rf_score_origem.mean())\n",
    "    # Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "    rf_origem_model.fit(X_train_origem, y_train_origem)\n",
    "    rf_origem_pred = rf_origem_model.predict(X_test_origem)\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "   # print(\"Relatório de Classificação (Teste):\")\n",
    "   # print(classification_report(y_test_origem, rf_origem_pred))\n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_origem, \n",
    "    rf_origem_pred,    output_dict=True)\n",
    "\n",
    "\n",
    "    return report_dict, rf_score_origem.mean(), rf_score_origem.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def processar_transicoes_com_label_encoder(df, modelo_origem):\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transition = df['Transition']\n",
    "\n",
    "    # Codificar as classes para y_origem, y_destino e y_transition\n",
    "    label_encoder_origem = LabelEncoder()\n",
    "    y_origem_encoded = label_encoder_origem.fit_transform(y_origem)\n",
    "\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "    y_destino_encoded = label_encoder_destino.fit_transform(y_destino)\n",
    "\n",
    "    label_encoder_transition = LabelEncoder()\n",
    "    y_transition_encoded = label_encoder_transition.fit_transform(y_transition)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transition_encoded, test_size=0.40, random_state=34, stratify=y_transition_encoded\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem_encoded[X_train_transition.index], y_origem_encoded[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino_encoded[X_train_transition.index], y_destino_encoded[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "\n",
    "    # Treinar e avaliar o modelo de Origem\n",
    "    rf_score_origem = cross_val_score(modelo_origem, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    #print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_origem.mean())\n",
    "    #print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_origem.std())\n",
    "\n",
    "    modelo_origem.fit(X_train_origem, y_train_origem)\n",
    "    origem_pred = modelo_origem.predict(X_test_origem)\n",
    "    origem_pred_test = modelo_origem.predict(X_test_transition)\n",
    "\n",
    "   \n",
    "\n",
    "    #print(\"Relatório de Classificação (Teste):\")\n",
    "    \n",
    "    #cm = classification_report(y_test_origem, origem_pred, target_names=label_encoder_origem.classes_ )\n",
    "    \n",
    "\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_origem, \n",
    "    origem_pred_test, \n",
    "    output_dict=True, target_names=label_encoder_origem.classes_)\n",
    "\n",
    " \n",
    "    \n",
    "  \n",
    "\n",
    "    return  report_dict , rf_score_origem.mean(),  rf_score_origem.std(), origem_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cid34senhas/miniconda3/envs/DAA123/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados Resumidos:\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|    | Modelo           |   F1 Macro (Score Médio) |   F1 Macro (Desvio Padrão) |\n",
      "+====+==================+==========================+============================+\n",
      "|  0 | ExtraTrees       |                 0.503472 |                  0.0527692 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  1 | RandomForest     |                 0.511629 |                  0.0722816 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  2 | GradientBoosting |                 0.548911 |                  0.0434801 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  3 | KNeighbors       |                 0.375457 |                  0.0350853 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  4 | SVC              |                 0.400301 |                  0.0554165 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "|  5 | XGBOOST          |                 0.521266 |                  0.0694838 |\n",
      "+----+------------------+--------------------------+----------------------------+\n",
      "\n",
      "Classification Reports:\n",
      "\n",
      "ExtraTrees - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.545455  0.250000  0.342857   24.000000\n",
      "CN             0.653061  0.761905  0.703297   42.000000\n",
      "MCI            0.564516  0.625000  0.593220   56.000000\n",
      "accuracy       0.598361  0.598361  0.598361    0.598361\n",
      "macro avg      0.587677  0.545635  0.546458  122.000000\n",
      "weighted avg   0.591249  0.598361  0.581864  122.000000\n",
      "\n",
      "RandomForest - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.562500  0.375000  0.450000   24.000000\n",
      "CN             0.640000  0.761905  0.695652   42.000000\n",
      "MCI            0.571429  0.571429  0.571429   56.000000\n",
      "accuracy       0.598361  0.598361  0.598361    0.598361\n",
      "macro avg      0.591310  0.569444  0.572360  122.000000\n",
      "weighted avg   0.593279  0.598361  0.590306  122.000000\n",
      "\n",
      "GradientBoosting - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.529412  0.375000  0.439024   24.000000\n",
      "CN             0.622642  0.785714  0.694737   42.000000\n",
      "MCI            0.596154  0.553571  0.574074   56.000000\n",
      "accuracy       0.598361  0.598361  0.598361    0.598361\n",
      "macro avg      0.582736  0.571429  0.569278  122.000000\n",
      "weighted avg   0.592143  0.598361  0.589047  122.000000\n",
      "\n",
      "KNeighbors - Classification Report\n",
      "              precision    recall  f1-score  support\n",
      "AD             0.363636  0.333333  0.347826     24.0\n",
      "CN             0.545455  0.714286  0.618557     42.0\n",
      "MCI            0.511111  0.410714  0.455446     56.0\n",
      "accuracy       0.500000  0.500000  0.500000      0.5\n",
      "macro avg      0.473401  0.486111  0.473943    122.0\n",
      "weighted avg   0.493923  0.500000  0.490428    122.0\n",
      "\n",
      "SVC - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.000000  0.000000  0.000000   24.000000\n",
      "CN             0.583333  0.666667  0.622222   42.000000\n",
      "MCI            0.513514  0.678571  0.584615   56.000000\n",
      "accuracy       0.540984  0.540984  0.540984    0.540984\n",
      "macro avg      0.365616  0.448413  0.402279  122.000000\n",
      "weighted avg   0.436531  0.540984  0.482556  122.000000\n",
      "\n",
      "XGBOOST - Classification Report\n",
      "              precision    recall  f1-score     support\n",
      "AD             0.500000  0.291667  0.368421   24.000000\n",
      "CN             0.603774  0.761905  0.673684   42.000000\n",
      "MCI            0.545455  0.535714  0.540541   56.000000\n",
      "accuracy       0.565574  0.565574  0.565574    0.565574\n",
      "macro avg      0.549743  0.529762  0.527549  122.000000\n",
      "weighted avg   0.556590  0.565574  0.552517  122.000000\n",
      "\n",
      "Top 3 Models based on F1 Macro Score for AD, CN, and MCI:\n",
      "1. RandomForest - F1 (AD): 0.4500, F1 (CN): 0.6957, F1 (MCI): 0.5714\n",
      "2. GradientBoosting - F1 (AD): 0.4390, F1 (CN): 0.6947, F1 (MCI): 0.5741\n",
      "3. ExtraTrees - F1 (AD): 0.3429, F1 (CN): 0.7033, F1 (MCI): 0.5932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Modelos\n",
    "modelos = {\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=447, max_features='sqrt', max_depth=15,\n",
    "        min_samples_split=10, min_samples_leaf=5, bootstrap=False, random_state=34\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=151, max_features='log2', max_depth=13,\n",
    "        min_samples_split=10, min_samples_leaf=3, bootstrap=True, random_state=34\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        learning_rate=0.1, n_estimators=100, random_state=34\n",
    "    ),\n",
    "    \"KNeighbors\": KNeighborsClassifier(\n",
    "        n_neighbors=5, weights='uniform', algorithm='auto'\n",
    "    ),\n",
    "    \"SVC\": SVC(\n",
    "        kernel='rbf', random_state=34\n",
    "    ),\n",
    "    \"XGBOOST\" : XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "}\n",
    "\n",
    "# Avaliação dos modelos e armazenamento dos resultados\n",
    "resultados = []\n",
    "classification_reports = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    # Chamar a função de processamento\n",
    "    report, f1_macro_score, f1_macro_std, previsoes_orgiem = processar_transicoes_com_label_encoder(df, modelo)\n",
    "    resultados.append({\n",
    "        \"Modelo\": nome,\n",
    "        \"F1 Macro (Score Médio)\": f1_macro_score,\n",
    "        \"F1 Macro (Desvio Padrão)\": f1_macro_std\n",
    "    })\n",
    "    \n",
    "    # Armazenar o classification report para exibição posterior\n",
    "    classification_reports[nome] = report\n",
    "\n",
    "# Converter resultados em tabela\n",
    "tabela_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Exibir tabela formatada\n",
    "print(\"\\nResultados Resumidos:\")\n",
    "print(tabulate(tabela_resultados, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "# Criar uma lista para armazenar os resultados de F1 macro para os três parâmetros\n",
    "f1_scores = []\n",
    "\n",
    "# Exibir classification reports de todos os modelos\n",
    "print(\"\\nClassification Reports:\")\n",
    "for nome, report in classification_reports.items():\n",
    "    print(f\"\\n{nome} - Classification Report\")\n",
    "    df_report = pd.DataFrame(report).transpose()  # Mostrar o report como DataFrame para facilitar leitura\n",
    "    print(df_report)\n",
    "\n",
    "    # Extrair os valores de F1 macro para AD, CN e MCI\n",
    "    f1_ad = report.get('AD', {}).get('f1-score', 0)\n",
    "    f1_cn = report.get('CN', {}).get('f1-score', 0)\n",
    "    f1_mci = report.get('MCI', {}).get('f1-score', 0)\n",
    "\n",
    "    # Armazenar os valores e o nome do modelo\n",
    "    f1_scores.append((nome, f1_ad, f1_cn, f1_mci))\n",
    "\n",
    "# Ordenar os modelos com base no F1 macro (média dos três parâmetros)\n",
    "f1_scores_sorted = sorted(f1_scores, key=lambda x: (x[1] + x[2] + x[3]) / 3, reverse=True)\n",
    "\n",
    "# Exibir os três melhores modelos com suas respectivas pontuações F1 macro\n",
    "print(\"\\nTop 3 Models based on F1 Macro Score for AD, CN, and MCI:\")\n",
    "for i, (nome, f1_ad, f1_cn, f1_mci) in enumerate(f1_scores_sorted[:3], 1):\n",
    "    print(f\"{i}. {nome} - F1 (AD): {f1_ad:.4f}, F1 (CN): {f1_cn:.4f}, F1 (MCI): {f1_mci:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m xgbost_origem \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,colsample_bytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m)\n\u001b[1;32m      4\u001b[0m random_forest_origem \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m report_xgboost, f1_macro_score_xgboost, f1_macro_std_xgboost \u001b[38;5;241m=\u001b[39m processar_transicoes_com_label_encoder(df,xgbost_origem)\n\u001b[1;32m      8\u001b[0m report_random, f1_macro_score_rf, f1_macro_std_rf \u001b[38;5;241m=\u001b[39m gerar_origem(df,random_forest_origem)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXgboost:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar instâncias dos modelos\n",
    "xgbost_origem = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "\n",
    "random_forest_origem = RandomForestClassifier(n_estimators=800,random_state=34)\n",
    "\n",
    "\n",
    "report_xgboost, f1_macro_score_xgboost, f1_macro_std_xgboost = processar_transicoes_com_label_encoder(df,xgbost_origem)\n",
    "report_random, f1_macro_score_rf, f1_macro_std_rf = gerar_origem(df,random_forest_origem)\n",
    "\n",
    "print(\"Xgboost:\")\n",
    "print(report_xgboost)\n",
    "print(\"F1_macro_Score:\")\n",
    "print(f1_macro_score_xgboost)\n",
    "print(\"F1_macro_Desvio_padrao:\")\n",
    "print(f1_macro_std_xgboost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
