{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        CN-CN\n",
      "1        CN-CN\n",
      "2        AD-AD\n",
      "3       CN-MCI\n",
      "4        CN-CN\n",
      "        ...   \n",
      "300      CN-CN\n",
      "301      CN-CN\n",
      "302     MCI-AD\n",
      "303    MCI-MCI\n",
      "304      CN-CN\n",
      "Name: Transition, Length: 305, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/cid34senhas/Desktop/DAATP/RawData/train_radiomics_hipocamp.csv') \n",
    "df_test = pd.read_csv('/home/cid34senhas/Desktop/DAATP/RawData/test_radiomics_hipocamp.csv')\n",
    "\n",
    "\n",
    "print(df['Transition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Value Colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.nunique() > 1]\n",
    "df_test = df_test.loc[:, df_test.nunique() > 1]\n",
    "\n",
    "#  Analise das colunas que tem menos de 50 valores unicos \n",
    "n = df.nunique()\n",
    "#for col, e in n.items():\n",
    "#    if e < 50:  \n",
    "#        print(f\"Coluna: {col}, Valores Unicos : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE BINING  ( secalhar isto era no 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_bins = [0, 65, 75, 85, 100]\n",
    "# BINS_SIZER = ['<65', '65-74', '75-84', '85+']\n",
    "age_labels = [60, 70, 80, 90] # VALOR MEDIO DO BIN \n",
    "df['Age'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "\n",
    "#print(df['Age'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colunas Categoricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar a contagem de valores únicos para cada coluna categórica\n",
    "\n",
    "# Identificar as colunas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "#for col in categorical_columns:\n",
    "#    print(f\"\\nColuna: {col}\")\n",
    "\n",
    "#colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash'] \n",
    "\n",
    "colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'] \n",
    "\n",
    "# ** Bounding Box\n",
    "#\n",
    "# ** as colunas do 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'\n",
    "# ** Deveriam ser retiradas, mas o bounding box pode ser importante para a zona de maior ativação do Alzimeir \n",
    "# **  ja a de centro de maxima devem ser muito correlacionados, por isso devem ser retirados mais para a frente \n",
    "# *TODO acabei por retirar para correr melhor os modelos, mas analisar se se deve retirar ou nao \n",
    "\n",
    "df.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)\n",
    "df_test.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar Transition CN-MCI \n",
    "\n",
    "Como este tipo de precisao não vai ser realiza, decidimos retirar todas as linhas com ela relacinadas para nao confundir o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Transition'] != 'CN-MCI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "    'CN-MCI' : 4\n",
    "}\n",
    "\n",
    "\n",
    "# Apply the mapping to the target column\n",
    "#df['Transition'] = df['Transition'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#experiment = setup(df, target='Transition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o tratamento atual, o pycaret diz que os melhores modelos são :\n",
    "- Random Forest Classifier\n",
    "- Extra Trees Classifier\n",
    "- Gradient Boosting Classifier \n",
    "- K Neighbors Classifier\n",
    "- Extreme Gradient Boosting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos (default) ao dataset tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0        CN-CN\n",
      "1        CN-CN\n",
      "2        AD-AD\n",
      "3       CN-MCI\n",
      "4        CN-CN\n",
      "        ...   \n",
      "300      CN-CN\n",
      "301      CN-CN\n",
      "302     MCI-AD\n",
      "303    MCI-MCI\n",
      "304      CN-CN\n",
      "Name: Transition, Length: 305, dtype: object\n",
      "    Origem Destino Transition\n",
      "0       CN      CN      CN-CN\n",
      "1       CN      CN      CN-CN\n",
      "2       AD      AD      AD-AD\n",
      "3       CN     MCI     CN-MCI\n",
      "4       CN      CN      CN-CN\n",
      "..     ...     ...        ...\n",
      "300     CN      CN      CN-CN\n",
      "301     CN      CN      CN-CN\n",
      "302    MCI      AD     MCI-AD\n",
      "303    MCI     MCI    MCI-MCI\n",
      "304     CN      CN      CN-CN\n",
      "\n",
      "[305 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df['Transition'].dtype)\n",
    "print(df['Transition'])\n",
    "\n",
    "df['Transition'] = df['Transition'].astype(str)\n",
    "\n",
    "df[['Origem', 'Destino']] = df['Transition'].str.split('-', expand=True)\n",
    "print(df[['Origem', 'Destino', 'Transition']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_transition_previsao(row, stats):\n",
    "    # Combinações válidas\n",
    "    combinacoes_validas = {'CN-CN', 'AD-AD', 'MCI-AD', 'MCI-MCI', 'CN-MCI'}\n",
    "\n",
    "    # Criar a combinação da origem e destino previstos\n",
    "    transition = f\"{row['Origem_Prevista']}-{row['Destino_Prevista']}\"\n",
    "\n",
    "    # Verificar se a combinação é válida\n",
    "    if transition in combinacoes_validas:\n",
    "        return transition\n",
    "    else:\n",
    "        # Regras para combinações inválidas\n",
    "        if row['Destino_Prevista'] == 'MCI' and row['Origem_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            print(\" row['Destino_Prevista'] == 'MCI' and row['Origem_Prevista'] not in {'MCI', 'CN'}:\")\n",
    "            return 'AD-AD'\n",
    "        elif row['Origem_Prevista'] == 'CN' and row['Destino_Prevista'] not in {'MCI', 'CN'}:\n",
    "            stats['alterados'] += 1\n",
    "            print(\" row['Origem_Prevista'] == 'CN' and row['Destino_Prevista'] not in {'MCI', 'CN'}:\")\n",
    "            return 'CN-MCI'\n",
    "        elif row['Destino_Prevista'] == 'AD' and row['Origem_Prevista'] != 'AD':\n",
    "            stats['alterados'] += 1\n",
    "            print(\"row['Destino_Prevista'] == 'AD' and row['Origem_Prevista'] != 'AD':\")\n",
    "            return 'AD-AD'\n",
    "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
    "            stats['alterados'] += 1\n",
    "            print(\"        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\")\n",
    "            return 'MCI-MCI'\n",
    "        else:\n",
    "            # Contar os casos que não foram corrigidos por falta de regra\n",
    "            stats['nao_corrigidos'] += 1\n",
    "            return transition  # Retorna o original, mesmo que inválido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_transicoes(df, modelo_origem, modelo_destino): \n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transtion = df['Transition']\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "\n",
    "    # Divisão principal para garantir que os índices de teste sejam os mesmos\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transtion, test_size=0.40, random_state=34, stratify=y_transtion\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem[X_train_transition.index], y_origem[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino[X_train_transition.index], y_destino[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    #\n",
    "\n",
    "\n",
    "    # ? ORIGEM #########################################################\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_origem_model = modelo_origem\n",
    "    # Avaliar desempenho com cross-validation no treino\n",
    "    rf_score_origem = cross_val_score(rf_origem_model, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation):\", rf_score_origem.mean())\n",
    "    # Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "    rf_origem_model.fit(X_train_origem, y_train_origem)\n",
    "    rf_origem_pred = rf_origem_model.predict(X_test_origem)\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_origem, rf_origem_pred))\n",
    "\n",
    "\n",
    "\n",
    "    # ? Destino #########################################################\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_destino_model = modelo_destino\n",
    "    # Avaliar desempenho com cross-validation no treino\n",
    "    rf_score_destino = cross_val_score(rf_destino_model, X_train_destino, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation):\", rf_score_destino.mean())\n",
    "    # Treinar o modelo no conjunto de treino e prever no conjunto de teste\n",
    "    rf_destino_model.fit(X_train_destino, y_train_destino)\n",
    "    rf_destino_pred = rf_destino_model.predict(X_test_destino)\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_destino, rf_destino_pred))\n",
    "\n",
    "\n",
    "\n",
    "    # Fazer previsões para o conjunto de teste\n",
    "    origem_pred_test = rf_origem_model.predict(X_test_transition)\n",
    "    destino_pred_test = rf_destino_model.predict(X_test_transition)\n",
    "\n",
    "    # Criar um DataFrame com as previsões do conjunto de teste\n",
    "    Previsoes_teste = pd.DataFrame({\n",
    "        'Origem_Prevista': origem_pred_test,\n",
    "        'Destino_Prevista': destino_pred_test\n",
    "    })\n",
    "\n",
    "    # Inicializar o dicionário para armazenar estatísticas\n",
    "    stats_test = {'alterados': 0, 'nao_corrigidos': 0}\n",
    "\n",
    "    # Gerar a coluna Transition-Previsao para o conjunto de teste\n",
    "    Previsoes_teste['Transition-Previsao'] = Previsoes_teste.apply(\n",
    "        gerar_transition_previsao, axis=1, stats=stats_test\n",
    "    )\n",
    "\n",
    "    # Comparar as previsões no conjunto de teste\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_transition, Previsoes_teste['Transition-Previsao']))\n",
    "\n",
    "    # Exibir contagens de alterações e casos não corrigidos\n",
    "    print(f\"Elementos alterados (teste): {stats_test['alterados']}\")\n",
    "    print(f\"Casos não corrigidos (teste): {stats_test['nao_corrigidos']}\")\n",
    "\n",
    "    res =  Previsoes_teste['Transition-Previsao'] \n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_transition, \n",
    "    Previsoes_teste['Transition-Previsao'], \n",
    "    output_dict=True)\n",
    "\n",
    "\n",
    "    return Previsoes_teste['Transition-Previsao'], report_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def processar_transicoes_com_label_encoder(df, modelo_origem, modelo_destino):\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transition = df['Transition']\n",
    "\n",
    "    # Codificar as classes para y_origem, y_destino e y_transition\n",
    "    label_encoder_origem = LabelEncoder()\n",
    "    y_origem_encoded = label_encoder_origem.fit_transform(y_origem)\n",
    "\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "    y_destino_encoded = label_encoder_destino.fit_transform(y_destino)\n",
    "\n",
    "    label_encoder_transition = LabelEncoder()\n",
    "    y_transition_encoded = label_encoder_transition.fit_transform(y_transition)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transition_encoded, test_size=0.40, random_state=34, stratify=y_transition_encoded\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem_encoded[X_train_transition.index], y_origem_encoded[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino_encoded[X_train_transition.index], y_destino_encoded[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "\n",
    "    # Treinar e avaliar o modelo de Origem\n",
    "    rf_score_origem = cross_val_score(modelo_origem, X_train_origem, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_origem.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_origem.std())\n",
    "\n",
    "    modelo_origem.fit(X_train_origem, y_train_origem)\n",
    "    origem_pred = modelo_origem.predict(X_test_origem)\n",
    "\n",
    "    # Treinar e avaliar o modelo de Destino\n",
    "    rf_score_destino = cross_val_score(modelo_destino, X_train_destino, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Destino):\", rf_score_destino.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Destino):\", rf_score_destino.std())\n",
    "\n",
    "    modelo_destino.fit(X_train_destino, y_train_destino)\n",
    "    destino_pred = modelo_destino.predict(X_test_destino)\n",
    "\n",
    "    # Fazer previsões para o conjunto de teste de Transition\n",
    "    origem_pred_test = modelo_origem.predict(X_test_transition)\n",
    "    destino_pred_test = modelo_destino.predict(X_test_transition)\n",
    "\n",
    "    # Decodificar as previsões para os valores originais\n",
    "    origem_pred_decoded = label_encoder_origem.inverse_transform(origem_pred_test)\n",
    "    destino_pred_decoded = label_encoder_destino.inverse_transform(destino_pred_test)\n",
    "\n",
    "    # Criar DataFrame de previsões\n",
    "    Previsoes_teste = pd.DataFrame({\n",
    "        'Origem_Prevista': origem_pred_decoded,\n",
    "        'Destino_Prevista': destino_pred_decoded\n",
    "    })\n",
    "\n",
    "    # Inicializar o dicionário de estatísticas\n",
    "    stats_test = {'alterados': 0, 'nao_corrigidos': 0}\n",
    "\n",
    "    # Gerar a coluna Transition-Previsao\n",
    "    Previsoes_teste['Transition-Previsao'] = Previsoes_teste.apply(\n",
    "        gerar_transition_previsao, axis=1, stats=stats_test\n",
    "    )\n",
    "\n",
    "    # Avaliar desempenho no conjunto de teste\n",
    "    y_test_transition_decoded = label_encoder_transition.inverse_transform(y_test_transition)\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_transition_decoded, Previsoes_teste['Transition-Previsao']))\n",
    "    \n",
    "    print(f\"Elementos alterados (teste): {stats_test['alterados']}\")\n",
    "    print(f\"Casos não corrigidos (teste): {stats_test['nao_corrigidos']}\")\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_transition_decoded, \n",
    "    Previsoes_teste['Transition-Previsao'], \n",
    "    output_dict=True\n",
    ")\n",
    "    return Previsoes_teste , report_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def processar_transicoes_com_label_encoder_reducao_features(df, modelo_origem, modelo_destino):\n",
    "    # Separar as features e os targets\n",
    "    X = df.drop(columns=['Origem', 'Destino', 'Transition'])\n",
    "    y_origem = df['Origem']\n",
    "    y_destino = df['Destino']\n",
    "    y_transition = df['Transition']\n",
    "\n",
    "    # Codificar as classes para y_origem, y_destino e y_transition\n",
    "    label_encoder_origem = LabelEncoder()\n",
    "    y_origem_encoded = label_encoder_origem.fit_transform(y_origem)\n",
    "\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "    y_destino_encoded = label_encoder_destino.fit_transform(y_destino)\n",
    "\n",
    "    label_encoder_transition = LabelEncoder()\n",
    "    y_transition_encoded = label_encoder_transition.fit_transform(y_transition)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste para validação\n",
    "    X_train_transition, X_test_transition, y_train_transition, y_test_transition = train_test_split(\n",
    "        X, y_transition_encoded, test_size=0.40, random_state=34, stratify=y_transition_encoded\n",
    "    )\n",
    "\n",
    "    # Usar os mesmos índices de treino e teste para y_origem e y_destino\n",
    "    y_train_origem, y_test_origem = y_origem_encoded[X_train_transition.index], y_origem_encoded[X_test_transition.index]\n",
    "    y_train_destino, y_test_destino = y_destino_encoded[X_train_transition.index], y_destino_encoded[X_test_transition.index]\n",
    "\n",
    "    X_train_origem, X_test_origem = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "    X_train_destino, X_test_destino = X.loc[X_train_transition.index], X.loc[X_test_transition.index]\n",
    "\n",
    "\n",
    "\n",
    "    modelo_origem.fit(X_train_origem, y_train_origem)\n",
    "    origem_pred = modelo_origem.predict(X_test_origem)\n",
    "\n",
    "##########\n",
    "    # Aplicar SelectFromModel para reduzir as features\n",
    "    selector = SelectFromModel(estimator=modelo_origem)\n",
    "    X_train_reduzido = selector.fit_transform(X_train_origem, y_train_origem)\n",
    "    X_test_reduzido = selector.transform(X_test_transition)\n",
    "    \n",
    "    # Exibir as dimensões antes e depois da redução\n",
    "    print(\"Dimensão original:\", X_train_origem.shape)\n",
    "    print(\"Dimensão reduzida:\", X_train_reduzido.shape)\n",
    "    \n",
    "    # Treinar o modelo com as features reduzidas\n",
    "    modelo_reduzido = modelo_origem\n",
    "    modelo_reduzido.fit(X_train_reduzido, y_train_origem)\n",
    "    y_pred_reduzido_origem = modelo_reduzido.predict(X_test_reduzido)\n",
    "\n",
    "\n",
    "        # Treinar e avaliar o modelo de Origem\n",
    "    rf_score_origem = cross_val_score(modelo_reduzido, X_train_reduzido, y_train_origem, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Origem):\", rf_score_origem.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Origem):\", rf_score_origem.std())\n",
    "############\n",
    "\n",
    "\n",
    "\n",
    "    modelo_destino.fit(X_train_destino, y_train_destino)\n",
    "    destino_pred = modelo_destino.predict(X_test_destino)\n",
    "\n",
    "    # Aplicar SelectFromModel para reduzir as features\n",
    "    selector = SelectFromModel(modelo_destino, threshold=\"median\")\n",
    "    X_train_reduzido = selector.fit_transform(X_train_destino, y_train_destino)\n",
    "    X_test_reduzido = selector.transform(X_test_transition)\n",
    "    \n",
    "    # Exibir as dimensões antes e depois da redução\n",
    "    print(\"Dimensão original:\", X_train_destino.shape)\n",
    "    print(\"Dimensão reduzida:\", X_train_reduzido.shape)\n",
    "    \n",
    "    # Treinar o modelo com as features reduzidas\n",
    "    modelo_reduzido =modelo_destino\n",
    "    modelo_reduzido.fit(X_train_reduzido, y_train_destino)\n",
    "    y_pred_reduzido = modelo_reduzido.predict(X_test_reduzido)\n",
    "\n",
    "\n",
    "\n",
    "    # Treinar e avaliar o modelo de Destino\n",
    "    rf_score_destino = cross_val_score(modelo_reduzido, X_train_reduzido, y_train_destino, cv=5, scoring='f1_macro')\n",
    "    print(\"F1 Macro (Cross-Validation - Destino):\", rf_score_destino.mean())\n",
    "    print(\"Desvio Padrão F1 Macro (Destino):\", rf_score_destino.std())\n",
    "################\n",
    "    # Fazer previsões para o conjunto de teste de Transition\n",
    "    #origem_pred_test = modelo_origem.predict(X_test_transition)\n",
    "    #destino_pred_test = modelo_destino.predict(X_test_transition)\n",
    "\n",
    "    # Decodificar as previsões para os valores originais\n",
    "    origem_pred_decoded = label_encoder_origem.inverse_transform(y_pred_reduzido_origem)\n",
    "    destino_pred_decoded = label_encoder_destino.inverse_transform(y_pred_reduzido)\n",
    "\n",
    "    # Criar DataFrame de previsões\n",
    "    Previsoes_teste = pd.DataFrame({\n",
    "        'Origem_Prevista': origem_pred_decoded,\n",
    "        'Destino_Prevista': destino_pred_decoded\n",
    "    })\n",
    "\n",
    "    # Inicializar o dicionário de estatísticas\n",
    "    stats_test = {'alterados': 0, 'nao_corrigidos': 0}\n",
    "\n",
    "    # Gerar a coluna Transition-Previsao\n",
    "    Previsoes_teste['Transition-Previsao'] = Previsoes_teste.apply(\n",
    "        gerar_transition_previsao, axis=1, stats=stats_test\n",
    "    )\n",
    "\n",
    "    # Avaliar desempenho no conjunto de teste\n",
    "    y_test_transition_decoded = label_encoder_transition.inverse_transform(y_test_transition)\n",
    "    print(\"Relatório de Classificação (Teste):\")\n",
    "    print(classification_report(y_test_transition_decoded, Previsoes_teste['Transition-Previsao']))\n",
    "    \n",
    "    print(f\"Elementos alterados (teste): {stats_test['alterados']}\")\n",
    "    print(f\"Casos não corrigidos (teste): {stats_test['nao_corrigidos']}\")\n",
    "\n",
    "    report_dict = classification_report(\n",
    "    y_test_transition_decoded, \n",
    "    Previsoes_teste['Transition-Previsao'], \n",
    "    output_dict=True\n",
    ")\n",
    "    return Previsoes_teste , report_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro (Cross-Validation): 0.5187944570049834\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.50      0.33      0.40        24\n",
      "          CN       0.66      0.79      0.72        42\n",
      "         MCI       0.57      0.57      0.57        56\n",
      "\n",
      "    accuracy                           0.60       122\n",
      "   macro avg       0.58      0.56      0.56       122\n",
      "weighted avg       0.59      0.60      0.59       122\n",
      "\n",
      "F1 Macro (Cross-Validation): 0.4843218957796963\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.74      0.82      0.78        51\n",
      "          CN       0.56      0.76      0.64        38\n",
      "         MCI       0.38      0.15      0.22        33\n",
      "\n",
      "    accuracy                           0.62       122\n",
      "   macro avg       0.56      0.58      0.55       122\n",
      "weighted avg       0.59      0.62      0.58       122\n",
      "\n",
      "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
      "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
      "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
      "        elif row['Origem_Prevista'] == 'MCI' and row['Destino_Prevista'] not in {'MCI', 'AD'}:\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AD-AD       0.50      0.33      0.40        24\n",
      "       CN-CN       0.60      0.76      0.67        38\n",
      "      CN-MCI       0.50      0.25      0.33         4\n",
      "      MCI-AD       0.29      0.44      0.35        27\n",
      "     MCI-MCI       0.40      0.21      0.27        29\n",
      "\n",
      "    accuracy                           0.46       122\n",
      "   macro avg       0.46      0.40      0.41       122\n",
      "weighted avg       0.46      0.46      0.44       122\n",
      "\n",
      "Elementos alterados (teste): 4\n",
      "Casos não corrigidos (teste): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0      MCI-AD\n",
       " 1       CN-CN\n",
       " 2      MCI-AD\n",
       " 3      MCI-AD\n",
       " 4      MCI-AD\n",
       "         ...  \n",
       " 117    MCI-AD\n",
       " 118    MCI-AD\n",
       " 119     AD-AD\n",
       " 120    MCI-AD\n",
       " 121    MCI-AD\n",
       " Name: Transition-Previsao, Length: 122, dtype: object,\n",
       " {'AD-AD': {'precision': 0.5,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.4,\n",
       "   'support': 24.0},\n",
       "  'CN-CN': {'precision': 0.6041666666666666,\n",
       "   'recall': 0.7631578947368421,\n",
       "   'f1-score': 0.6744186046511628,\n",
       "   'support': 38.0},\n",
       "  'CN-MCI': {'precision': 0.5,\n",
       "   'recall': 0.25,\n",
       "   'f1-score': 0.3333333333333333,\n",
       "   'support': 4.0},\n",
       "  'MCI-AD': {'precision': 0.2926829268292683,\n",
       "   'recall': 0.4444444444444444,\n",
       "   'f1-score': 0.35294117647058826,\n",
       "   'support': 27.0},\n",
       "  'MCI-MCI': {'precision': 0.4,\n",
       "   'recall': 0.20689655172413793,\n",
       "   'f1-score': 0.2727272727272727,\n",
       "   'support': 29.0},\n",
       "  'accuracy': 0.45901639344262296,\n",
       "  'macro avg': {'precision': 0.459369918699187,\n",
       "   'recall': 0.39956644484775156,\n",
       "   'f1-score': 0.4066840774364714,\n",
       "   'support': 122.0},\n",
       "  'weighted avg': {'precision': 0.4627932160469146,\n",
       "   'recall': 0.45901639344262296,\n",
       "   'f1-score': 0.4426208441301173,\n",
       "   'support': 122.0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#\n",
    "## Criar instâncias dos modelos\n",
    "#xgbost_origem = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "#xgbost_destino = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "#\n",
    "random_forest_origem = RandomForestClassifier(n_estimators=800,random_state=34)\n",
    "random_forest_destino = RandomForestClassifier(n_estimators=800,random_state=34)\n",
    "processar_transicoes(df,random_forest_origem,random_forest_destino)\n",
    "#\n",
    "## Chamar a função com as instâncias dos modelos\n",
    "#previsoes_xgboosd, report_classificacao_xgboost = processar_transicoes_com_label_encoder(df, xgbost_origem, xgbost_destino)\n",
    "#\n",
    "#previsoes_random_forest, report_classificacao_random_forest = processar_transicoes(df, random_forest_origem,random_forest_destino)\n",
    "##grandient_origem  = GradientBoostingClassifier(\n",
    "##        learning_rate=0.1, n_estimators=100, random_state=34\n",
    "##    )\n",
    "##extra_trees_destino =  ExtraTreesClassifier(\n",
    "##        n_estimators=447, max_features='sqrt', max_depth=15,\n",
    "##        min_samples_split=10, min_samples_leaf=5, bootstrap=False, random_state=34\n",
    "##    )\n",
    "##previsoes, report_classificacao_xgboost = processar_transicoes_com_label_encoder_reducao_features(df, grandient_origem, grandient_origem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_predictions_csv(\n",
    "    origem_model: ClassifierMixin, \n",
    "    destino_model: ClassifierMixin, \n",
    "    test_data_set: pd.DataFrame, \n",
    "):\n",
    "    \"\"\"\n",
    "    Gera um arquivo CSV com as previsões combinadas de dois modelos fornecidos e o conjunto de teste.\n",
    "    Inclui estatísticas de transições corrigidas e não corrigidas.\n",
    "\n",
    "    Parameters:\n",
    "    - origem_model: Modelo treinado para prever a origem.\n",
    "    - destino_model: Modelo treinado para prever o destino.\n",
    "    - test_data_set: DataFrame com os dados de teste.\n",
    "    \"\"\"\n",
    "    # Fazer previsões para o conjunto de teste\n",
    "    origem_pred_test = origem_model.predict(test_data_set)\n",
    "    destino_pred_test = destino_model.predict(test_data_set)\n",
    "\n",
    "    # Criar um DataFrame com as previsões do conjunto de teste\n",
    "    Previsoes_teste = pd.DataFrame({\n",
    "        'Origem_Prevista': origem_pred_test,\n",
    "        'Destino_Prevista': destino_pred_test\n",
    "    })\n",
    "\n",
    "    # Inicializar o dicionário para armazenar estatísticas\n",
    "    stats_test = {'alterados': 0, 'nao_corrigidos': 0}\n",
    "\n",
    "    # Gerar a coluna Transition-Previsao para o conjunto de teste\n",
    "    Previsoes_teste['Transition-Previsao'] = Previsoes_teste.apply(\n",
    "        gerar_transition_previsao, axis=1, stats=stats_test\n",
    "    )\n",
    "\n",
    "    # Renomear a coluna 'Transition-Previsao' para 'Result'\n",
    "    Previsoes_teste.rename(columns={'Transition-Previsao': 'Result'}, inplace=True)\n",
    "\n",
    "    # Exibir contagens de alterações e casos não corrigidos\n",
    "    print(f\"Elementos alterados (teste): {stats_test['alterados']}\")\n",
    "    print(f\"Casos não corrigidos (teste): {stats_test['nao_corrigidos']}\")\n",
    "\n",
    "    # Salvar o DataFrame em um arquivo CSV\n",
    "    Previsoes_teste.index = range(1, len(Previsoes_teste) + 1)\n",
    "    Previsoes_teste.index.name = 'RowId'\n",
    "    output_filename = f\"{type(origem_model).__name__}_{type(destino_model).__name__}_predictions.csv\"\n",
    "    Previsoes_teste.to_csv(output_filename, columns=['Result'], index=True)\n",
    "\n",
    "    print(f\"Resultados salvos no arquivo {output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#generate_predictions_csv(modelo_origem,modelo_destino,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_predictions_csv_com_label_enconder(\n",
    "    origem_model, \n",
    "    destino_model, \n",
    "    test_data_set: pd.DataFrame\n",
    "):\n",
    "    \"\"\"\n",
    "    Gera um arquivo CSV com as previsões combinadas de dois modelos fornecidos e o conjunto de teste,\n",
    "    utilizando LabelEncoder para mapear os rótulos.\n",
    "\n",
    "    Parameters:\n",
    "    - origem_model: Modelo treinado para prever a origem.\n",
    "    - destino_model: Modelo treinado para prever o destino.\n",
    "    - test_data_set: DataFrame com os dados de teste (apenas features, sem rótulos).\n",
    "    \"\"\"\n",
    "    # Criar LabelEncoders para os rótulos de origem e destino\n",
    "    label_encoder_origem = LabelEncoder()\n",
    "    label_encoder_destino = LabelEncoder()\n",
    "\n",
    "    # Definir os rótulos conhecidos (substitua por seus valores reais)\n",
    "    known_origem_labels = ['CN', 'AD', 'MCI']  # Exemplo de rótulos possíveis para \"Origem\"\n",
    "    known_destino_labels = ['CN', 'AD', 'MCI']  # Exemplo de rótulos possíveis para \"Destino\"\n",
    "\n",
    "    # Ajustar os encoders com os rótulos conhecidos\n",
    "    label_encoder_origem.fit(known_origem_labels)\n",
    "    label_encoder_destino.fit(known_destino_labels)\n",
    "\n",
    "    # Fazer previsões usando os modelos\n",
    "    origem_pred = origem_model.predict(test_data_set)\n",
    "    destino_pred = destino_model.predict(test_data_set)\n",
    "\n",
    "    # Decodificar as previsões para rótulos textuais\n",
    "    origem_pred_decoded = label_encoder_origem.inverse_transform(origem_pred)\n",
    "    destino_pred_decoded = label_encoder_destino.inverse_transform(destino_pred)\n",
    "\n",
    "    # Criar um DataFrame com as previsões\n",
    "    Previsoes_teste = pd.DataFrame({\n",
    "        'Origem_Prevista': origem_pred_decoded,\n",
    "        'Destino_Prevista': destino_pred_decoded\n",
    "    })\n",
    "\n",
    "    # Gerar coluna combinada (Transition-Previsao)\n",
    "    stats_test = {'alterados': 0, 'nao_corrigidos': 0}\n",
    "\n",
    "        # Gerar a coluna Transition-Previsao\n",
    "    Previsoes_teste['Result'] = Previsoes_teste.apply(\n",
    "        gerar_transition_previsao, axis=1, stats=stats_test\n",
    "    )\n",
    "\n",
    "    print(f\"Elementos alterados (teste): {stats_test['alterados']}\")\n",
    "    print(f\"Casos não corrigidos (teste): {stats_test['nao_corrigidos']}\")\n",
    "    # Salvar previsões em um arquivo CSV\n",
    "    Previsoes_teste.index = range(1, len(Previsoes_teste) + 1)\n",
    "    Previsoes_teste.index.name = 'RowId'\n",
    "    output_filename = f\"{type(origem_model).__name__}_{type(destino_model).__name__}_predictions.csv\"\n",
    "    Previsoes_teste.to_csv(output_filename, columns=[ 'Result'], index=True)\n",
    "\n",
    "    print(f\"Resultados salvos no arquivo {output_filename}\")\n",
    "    return Previsoes_teste\n",
    "\n",
    "#generate_predictions_csv_com_label_enconder(modelo_origem,modelo_destino,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAA123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
