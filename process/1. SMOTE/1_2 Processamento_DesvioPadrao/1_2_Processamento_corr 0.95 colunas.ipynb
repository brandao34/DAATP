{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEITURA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (305, 2181)\n",
      "Shape of df_test: (100, 2180)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../RawData/train_radiomics_hipocamp.csv') \n",
    "df_test = pd.read_csv('../../RawData/test_radiomics_hipocamp.csv')\n",
    "\n",
    "print(f\"Shape of df: {df.shape}\")\n",
    "print(f\"Shape of df_test: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Value Colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.nunique() > 1]\n",
    "df_test = df_test.loc[:, df_test.nunique() > 1]\n",
    "\n",
    "\n",
    "#  Analise das colunas que tem menos de 50 valores unicos \n",
    "#n = df.nunique()\n",
    "#for col, e in n.items():\n",
    "#    if e < 50:  \n",
    "#        print(f\"Coluna: {col}, Valores Unicos : {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGE BINING  ( secalhar isto era no 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age_bins = [0, 65, 75, 85, 100]\n",
    "# BINS_SIZER = ['<65', '65-74', '75-84', '85+']\n",
    "age_labels = [60, 70, 80, 90] # VALOR MEDIO DO BIN \n",
    "df['Age'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins=age_bins, labels=age_labels).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colunas Categoricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar a contagem de valores únicos para cada coluna categórica\n",
    "\n",
    "# Identificar as colunas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "#for col in categorical_columns:\n",
    "#    print(f\"\\nColuna: {col}\")\n",
    "\n",
    "#colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash'] \n",
    "\n",
    "colunas_catagoricas_a_remover = ['ID', 'Image', 'Mask', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'] \n",
    "\n",
    "# ** Bounding Box\n",
    "#\n",
    "# ** as colunas do 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'\n",
    "# ** Deveriam ser retiradas, mas o bounding box pode ser importante para a zona de maior ativação do Alzimeir \n",
    "# **  ja a de centro de maxima devem ser muito correlacionados, por isso devem ser retirados mais para a frente \n",
    "# *TODO acabei por retirar para correr melhor os modelos, mas analisar se se deve retirar ou nao \n",
    "\n",
    "df.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)\n",
    "df_test.drop(columns=colunas_catagoricas_a_remover,axis= 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar Transition CN-MCI && Label_Mapping\n",
    "\n",
    "Como este tipo de precisao não vai ser realiza, decidimos retirar todas as linhas com ela relacinadas para nao confundir o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Transition'] != 'CN-MCI']\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'CN-CN': 0,\n",
    "    'AD-AD': 1,\n",
    "    'MCI-AD': 2,\n",
    "    'MCI-MCI': 3,\n",
    "#    'CN-MCI' : 4\n",
    "}\n",
    "# Apply the mapping to the target column\n",
    "df['Transition'] = df['Transition'].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlacao com target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 2014)\n",
      "(295, 1661)\n",
      "(100, 1660)\n"
     ]
    }
   ],
   "source": [
    "def remove_highly_correlated_with_target(data, target_column, threshold):\n",
    "    # Compute the correlation of each column with the target column\n",
    "    corr_with_target = data.corr()[target_column].abs()\n",
    "    \n",
    "    # Identify columns to remove based on correlation with the target\n",
    "    to_drop = corr_with_target[corr_with_target >= threshold].index\n",
    "    to_drop = to_drop.drop(target_column)  # Remove target column itself if included\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    data_final = data.drop(columns=to_drop)\n",
    "\n",
    "    return data_final, to_drop\n",
    "print(df.shape)\n",
    "df, to_drop4 = remove_highly_correlated_with_target(df, 'Transition',threshold=0.18)\n",
    "df_test =  df_test.drop(columns=to_drop4)\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlacao colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 1661)\n",
      "(295, 843)\n",
      "(100, 842)\n"
     ]
    }
   ],
   "source": [
    "def remove_highly_correlated_features(data, threshold):\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = data.corr().abs()\n",
    "\n",
    "    # Identify columns to remove based on correlation\n",
    "    to_drop = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i + 1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] >= threshold:\n",
    "                to_drop.add(corr_matrix.columns[j])\n",
    "\n",
    "    # Drop the identified columns\n",
    "    data_final = data.drop(columns=to_drop)\n",
    "\n",
    "    return data_final, to_drop\n",
    "\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df, to_drop5 = remove_highly_correlated_features(df,0.95)\n",
    "df_test =  df_test.drop(columns=to_drop5)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desvio Padrao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 843)\n",
      "(295, 843)\n",
      "(100, 842)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "def remove_low_variance_features(data, threshold):\n",
    "    # Seleciona colunas numéricas\n",
    "    numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    # Remove features de baixa variância\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    low_variance_data = selector.fit_transform(numeric_data)\n",
    "    print(low_variance_data.size)\n",
    "    # Colunas retidas\n",
    "    retained_columns = numeric_data.columns[selector.get_support(indices=True)]\n",
    "    print(retained_columns.size)\n",
    "    # Colunas descartadas\n",
    "    # Cria um DataFrame com as colunas retidas\n",
    "    data_reduced = pd.DataFrame(low_variance_data, columns=retained_columns)\n",
    "    \n",
    "\n",
    "    return data_reduced\n",
    "print(df.shape)\n",
    "#df, to_drop3  = remove_low_variance_features(df,0.01)\n",
    "#to_drop3 = to_drop3.drop('Transition')\n",
    "#df_test = df_test.drop(columns=to_drop3)\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imprimir dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/cid34senhas/Desktop/DAATP/Data/5. Data APOS 1_2 sem desvio padrao.csv\")\n",
    "df_test.to_csv(\"/home/cid34senhas/Desktop/DAATP/Data/5. Data TEST APOS 1_2 sem desviopadra.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#experiment = setup(df, target='Transition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o tratamento atual, o pycaret diz que os melhores modelos são :\n",
    "- Random Forest Classifier\n",
    "- Extra Trees Classifier\n",
    "- Gradient Boosting Classifier \n",
    "- K Neighbors Classifier\n",
    "- Extreme Gradient Boosting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação dos modelos (default) ao dataset tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop('Transition', axis=1)\n",
    "#y = df['Transition']\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "#\n",
    "#smote = SMOTE(sampling_strategy=\"auto\", random_state=34)\n",
    "#X_res, y_res = smote.fit_resample(X, y)\n",
    "#print('Resampled dataset shape %s %s' % X_res.shape,y_res.shape)\n",
    "#print(\"Y Smote Values:\")\n",
    "#y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separar as features e o target\n",
    "X = df.drop('Transition', axis=1)\n",
    "y = df['Transition']\n",
    "\n",
    "# Dividir o conjunto de dados em treino e teste com estratificação\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"auto\", random_state=34)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Inicializar dicionário para armazenar as pontuações de cross-validation do modelo\n",
    "model_cross_score = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y Res Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transition\n",
       "3    72\n",
       "0    72\n",
       "1    72\n",
       "2    72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Y Res Values\")\n",
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcao axuliar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_labels(confusion_matrix, label_mapping):\n",
    "    # Criar um mapeamento inverso\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    \n",
    "    # Aplicar o mapeamento inverso na matriz de confusão\n",
    "    cm_with_labels = np.zeros_like(confusion_matrix, dtype=object)\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            cm_with_labels[i, j] = f\"{reverse_label_mapping[i]} (Pred: {reverse_label_mapping[j]})\"\n",
    "\n",
    "    # Criar um DataFrame para facilitar a visualização\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=reverse_label_mapping.values(), columns=reverse_label_mapping.values())\n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix with Labels')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m)\n\u001b[1;32m      3\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_res, y_res)\n\u001b[1;32m      6\u001b[0m rf_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=34)\n",
    "\n",
    "rf_model.fit(X_res, y_res)\n",
    "\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred))\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "plot_confusion_matrix_with_labels(cm,label_mapping)\n",
    "\n",
    "model_cross_score['random_forest'] = cross_val_score(rf_model, X_test, y_test, cv=5).mean()\n",
    "print(f\"Cross validation score:{model_cross_score['random_forest']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59        24\n",
      "           1       0.50      0.60      0.55        15\n",
      "           2       0.08      0.06      0.07        17\n",
      "           3       0.40      0.22      0.29        18\n",
      "\n",
      "    accuracy                           0.42        74\n",
      "   macro avg       0.37      0.40      0.37        74\n",
      "weighted avg       0.38      0.42      0.39        74\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4189189189189189\n",
      "0.7192982456140351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, et_pred))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(cross_val_score(et_model,X_res,y_res,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m---> 11\u001b[0m model_cross_score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtra Trees\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cross_val_score(et_model, X_res, y_res, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross validation score:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_cross_score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtra Trees\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:887\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    883\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclone(parameters, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    885\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 887\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m    888\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[1;32m    890\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/metaestimators.py:158\u001b[0m, in \u001b[0;36m_safe_split\u001b[0;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[1;32m    156\u001b[0m         X_subset \u001b[38;5;241m=\u001b[39m X[np\u001b[38;5;241m.\u001b[39mix_(indices, train_indices)]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     X_subset \u001b[38;5;241m=\u001b[39m _safe_indexing(X, indices)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     y_subset \u001b[38;5;241m=\u001b[39m _safe_indexing(y, indices)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/__init__.py:407\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# TODO: we should probably use _is_pandas_df(X) instead but this would\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# require updating some tests such as test_train_test_split_mock_pandas.\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_polars_df(X):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/utils/__init__.py:219\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    214\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(key)):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mtake(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/pandas/core/generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4066\u001b[0m     )\n\u001b[0;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   4069\u001b[0m     indices,\n\u001b[1;32m   4070\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   4071\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4072\u001b[0m )\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4075\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/pandas/core/internals/managers.py:877\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    878\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    879\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[1;32m    880\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    881\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    882\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    883\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/pandas/core/internals/managers.py:671\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    664\u001b[0m         indexer,\n\u001b[1;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 671\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    672\u001b[0m             indexer,\n\u001b[1;32m    673\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    674\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    675\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    676\u001b[0m             ),\n\u001b[1;32m    677\u001b[0m         )\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    679\u001b[0m     ]\n\u001b[1;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1079\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values, new_mgr_locs)\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1079\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block_same_class(new_values, new_mgr_locs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/pandas/core/internals/blocks.py:265\u001b[0m, in \u001b[0;36mBlock.make_block_same_class\u001b[0;34m(self, values, placement, refs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_block(values, placement\u001b[38;5;241m=\u001b[39mplacement, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim, refs\u001b[38;5;241m=\u001b[39mrefs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_block_same_class\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     values,\n\u001b[1;32m    269\u001b[0m     placement: BlockPlacement \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    270\u001b[0m     refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    271\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrap given values in a block of same type as self.\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m#  relied on it, as of 2.0 the caller is responsible for this.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "et_model = ExtraTreesClassifier(criterion='gini', max_depth=20, random_state=34)\n",
    "et_model.fit(X_res, y_res)\n",
    "et_pred = et_model.predict(X_test)\n",
    "print(classification_report(y_test,et_pred))\n",
    "cm = confusion_matrix(y_test,et_pred)\n",
    "plot_confusion_matrix_with_labels(cm, label_mapping)\n",
    "plt.show\n",
    "print(accuracy_score(y_test, et_pred))\n",
    "print(cross_val_score(et_model,X_res,y_res,cv=5).mean())\n",
    "\n",
    "model_cross_score['Extra Trees'] = cross_val_score(et_model, X_res, y_res, cv=5).mean()\n",
    "print(f\"Cross validation score:{model_cross_score['Extra Trees']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m gb_model\u001b[38;5;241m.\u001b[39mfit(X_res, y_res)\n\u001b[1;32m      3\u001b[0m gb_pred \u001b[38;5;241m=\u001b[39m gb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test,gb_pred))\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[1;32m    785\u001b[0m     X_train,\n\u001b[1;32m    786\u001b[0m     y_train,\n\u001b[1;32m    787\u001b[0m     raw_predictions,\n\u001b[1;32m    788\u001b[0m     sample_weight_train,\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[1;32m    790\u001b[0m     X_val,\n\u001b[1;32m    791\u001b[0m     y_val,\n\u001b[1;32m    792\u001b[0m     sample_weight_val,\n\u001b[1;32m    793\u001b[0m     begin_at_stage,\n\u001b[1;32m    794\u001b[0m     monitor,\n\u001b[1;32m    795\u001b[0m )\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    877\u001b[0m         )\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[1;32m    881\u001b[0m     i,\n\u001b[1;32m    882\u001b[0m     X,\n\u001b[1;32m    883\u001b[0m     y,\n\u001b[1;32m    884\u001b[0m     raw_predictions,\n\u001b[1;32m    885\u001b[0m     sample_weight,\n\u001b[1;32m    886\u001b[0m     sample_mask,\n\u001b[1;32m    887\u001b[0m     random_state,\n\u001b[1;32m    888\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[1;32m    889\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[1;32m    890\u001b[0m )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 490\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    491\u001b[0m     X, neg_g_view[:, k], sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1378\u001b[0m         X,\n\u001b[1;32m   1379\u001b[0m         y,\n\u001b[1;32m   1380\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1381\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/Daa312/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, random_state=34)\n",
    "gb_model.fit(X_res, y_res)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "print(classification_report(y_test,gb_pred))\n",
    "cm = confusion_matrix(y_test,gb_pred)\n",
    "plot_confusion_matrix_with_labels(cm,label_mapping)\n",
    "plt.show\n",
    "print(accuracy_score(y_test, gb_pred))\n",
    "score_cross = cross_val_score(gb_model,X_res,y_res,cv=5).mean()\n",
    "\n",
    "\n",
    "model_cross_score['Gradient_boosting'] = score_cross\n",
    "\n",
    "print(f\"Cross validation score:{model_cross_score['Gradient_boosting']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.05,colsample_bytree=0.4, subsample=0.8, random_state=34)\n",
    "xgb_model.fit(X_res, y_res)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test,xgb_pred))\n",
    "cm = confusion_matrix(y_test,xgb_pred)\n",
    "plot_confusion_matrix_with_labels(cm,label_mapping)\n",
    "plt.show\n",
    "print(accuracy_score(y_test, xgb_pred))\n",
    "\n",
    "\n",
    "score_cross = cross_val_score(xgb_model,X_res,y_res,cv=5).mean()\n",
    "\n",
    "\n",
    "print(f\"Cross validation score:{score_cross}\")\n",
    "\n",
    "\n",
    "model_cross_score['XGBoost'] = score_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Numero de Colunas\")\n",
    "print(X_train.shape)\n",
    "print(\"Numero de Colunas com Smote\")\n",
    "print(X_res.shape)\n",
    "\n",
    "\n",
    "# função que compara os modelos, para isso, usa um dicionário {\"Model Name: [predictions], ...\"}\n",
    "def compare_models(Y_test, predictions):\n",
    "    # Create a dictionary of models and their respective accuracies\n",
    "    model_accuracies = {}\n",
    "    for name, prediction in predictions.items():\n",
    "        # Calculate the accuracy for each model\n",
    "        accuracy = sum(prediction == Y_test) / len(Y_test)\n",
    "        # Add the model and its accuracy to the dictionary\n",
    "        model_accuracies[name] = accuracy\n",
    "\n",
    "    # Sort the models by their accuracy in ascending order\n",
    "    sorted_models = sorted(model_accuracies, key=model_accuracies.get)\n",
    "\n",
    "    # Print the table with the accuracy of each model\n",
    "    print(\"Model\".ljust(20), \"Accuracy\")\n",
    "    print(\"-\" * 30)\n",
    "    for model in sorted_models:\n",
    "        print(model.ljust(20), str(model_accuracies[model]).rjust(10))\n",
    "\n",
    "\n",
    "predictions = {\n",
    "    'Random Forest Classifier' : rf_pred,\n",
    "    'Extra Trees Classifier' : et_pred,\n",
    "    'Gradient Boosting Classifier' : gb_pred,\n",
    "    'Extreme Gradient Boosting' : xgb_pred\n",
    "}\n",
    "\n",
    "compare_models(y_test, predictions)\n",
    "\n",
    "\n",
    "def compare_models_cross_score(model_cross_score):\n",
    "    # Sort models by cross-validation score in descending order\n",
    "    sorted_models = sorted(model_cross_score.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the table with the cross-validation score of each model\n",
    "    print(\"Model\".ljust(30), \"Cross-Validation Score\")\n",
    "    print(\"-\" * 45)\n",
    "    for model, score in sorted_models:\n",
    "        print(model.ljust(30), f\"{score:.4f}\".rjust(10))\n",
    "\n",
    "\n",
    "\n",
    "compare_models_cross_score(model_cross_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Daa312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
